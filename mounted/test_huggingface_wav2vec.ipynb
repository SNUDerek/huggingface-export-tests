{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34123c5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# References\n",
    "\n",
    "- (torch) https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html\n",
    "- (reproducibility) https://pytorch.org/docs/stable/notes/randomness.html\n",
    "- (torchscript) https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html\n",
    "- (onnx export) https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html\n",
    "- (import example) https://colab.research.google.com/github/PyThaiNLP/tutorials/blob/master/source/notebooks/thai_wav2vec2_onnx.ipynb#scrollTo=5-lBGrVVj0i_\n",
    "- (onnx FP16) https://github.com/onnx/onnx-docker/blob/master/onnx-ecosystem/converter_scripts/float32_float16_onnx.ipynb\n",
    "- (onnxruntime) https://onnxruntime.ai/docs/get-started/with-python.html\n",
    "- (tensorrt saving, inference) https://developer.nvidia.com/blog/speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt/\n",
    "- (tensorrt inference, fixed) https://stackoverflow.com/questions/59280745/inference-with-tensorrt-engine-file-on-python\n",
    "- (torch-tensorrt) https://developer.nvidia.com/blog/accelerating-inference-up-to-6x-faster-in-pytorch-with-torch-tensorrt/\n",
    "- (torch-tensorrt python) https://nvidia.github.io/Torch-TensorRT/tutorials/getting_started_with_python_api.html\n",
    "- model info: https://huggingface.co/facebook/wav2vec2-base-960h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef2c6d1-2733-480e-a305-ac6583678d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4daa0adc-73ad-4dd3-bfe8-434d7ef75d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility with CUDA 11+ and GPU inference\n",
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG']=':4096:8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cc88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxmltools\n",
    "import onnxruntime\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit \n",
    "import random\n",
    "import time\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torch_tensorrt\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import soundfile as sf\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "from torchaudio.models.wav2vec2.utils import import_huggingface_model\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from pynvml import *\n",
    "nvmlInit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9ece0c-8d51-434c-891f-0863c596b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce randomness for reproducibility\n",
    "torch.manual_seed(1337)\n",
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "# torch.use_deterministic_algorithms(True) # error with cuda 11+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf1897-d863-406b-a5ba-813f633055d4",
   "metadata": {},
   "source": [
    "### check import versions, cuda support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7e91f1-bf6b-4f97-9923-bd49dabd271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii  libnvinfer-bin                  8.2.1-1+cuda11.4                  amd64        TensorRT binaries\n",
      "ii  libnvinfer-dev                  8.2.1-1+cuda11.4                  amd64        TensorRT development libraries and headers\n",
      "ii  libnvinfer-plugin-dev           8.2.1-1+cuda11.4                  amd64        TensorRT plugin libraries and headers\n",
      "ii  libnvinfer-plugin8              8.2.1-1+cuda11.4                  amd64        TensorRT plugin library\n",
      "ii  libnvinfer8                     8.2.1-1+cuda11.4                  amd64        TensorRT runtime libraries\n"
     ]
    }
   ],
   "source": [
    "!dpkg -l | grep nvinfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfdcdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.10.1+cu113\n",
      "pytorch cuda?  : True\n"
     ]
    }
   ],
   "source": [
    "print(\"pytorch version:\", torch.__version__)\n",
    "print(\"pytorch cuda?  :\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6addd82a-b124-4055-869e-41d58ffa7c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnxruntime version: 1.9.0\n",
      "onnxruntime device : GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"onnxruntime version:\", onnxruntime.__version__)\n",
    "print(\"onnxruntime device :\", onnxruntime.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63834519-cd94-4e65-b2a3-09343a8ed1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 stats:\n",
      "total    : 11534336.00 MB\n",
      "free     : 11125440.00 MB\n",
      "used     :   408896.00 MB\n"
     ]
    }
   ],
   "source": [
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(\"GPU 0 stats:\")\n",
    "print(f'total    : {info.total/1024.:>11.2f} MB')\n",
    "print(f'free     : {info.free/1024.:>11.2f} MB')\n",
    "print(f'used     : {info.used/1024.:>11.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e9c25-5152-4540-b6d7-5844345ba5a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## export HuggingFace to PyTorch\n",
    "\n",
    "huggingface has a direct onnx export, but it only supports some model types, not including wav2vec.\n",
    "\n",
    "`torchaudio` has a utility to import HuggingFace Wav2Vec2 models, so we'll import the model to pytorch and export with pyotrch's onnx export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15df278c-ac6b-40da-ac4e-2ef8fdc35092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset librispeech_asr (/root/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr/clean/2.1.0/f2c70a4d03ab4410954901bde48c54b85ca1b7f9bf7d616e7e2a72b5ee6ddbfc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6de4a4871748518e7da52e58a66924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample data for testing\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2740f23d-f3ec-44b4-bd7c-5db71667e6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93680,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'][0][\"audio\"][\"array\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d806022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy input\n",
    "AUDIO_MAXLEN = 100000\n",
    "dummy_input = torch.randn(1, AUDIO_MAXLEN, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a3ebdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# (down)load model and tokenizer\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "hugging_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3122823e-034b-43b7-8687-69eaa12b01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import as native pytorch model\n",
    "_ = hugging_model.eval()\n",
    "imported_model = import_huggingface_model(hugging_model)\n",
    "gpu_model = import_huggingface_model(hugging_model)\n",
    "_ = imported_model.eval()\n",
    "_ = gpu_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6685979-596f-4f5b-bf47-780b07dde545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAD4CAYAAABog7YvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABxEElEQVR4nO3dd3hU1dYG8HenkFASaqgBQu89UqQXKaJg7/Wq2PWzY0dF4YpdsWCXa1dUFJDee+gdAgQINfSQkL6/P2YmTJLpp595f8/jY2bmzDk7YeaUddZeS0gpQURERERERERE4S3C6AEQEREREREREZHxGCQiIiIiIiIiIiIGiYiIiIiIiIiIiEEiIiIiIiIiIiICg0RERERERERERAQgyugBeFOjRg2ZlJRk9DCIiIiIiIiIiGxjzZo1x6WUCZ5eM22QKCkpCSkpKUYPg4iIiIiIiIjINoQQ+7y9xulmRERERERERETEIBEREREREREREakUJBJCDBVC7BBCpAohRvtY7mohhBRCJKuxXSIiIiIiIiIiUofiIJEQIhLARADDALQGcKMQorWH5eIAPApgpdJtEhERERERERGRutTIJOoKIFVKuUdKmQfgJwAjPSz3GoD/AshRYZtERERERERERKQiNYJE9QAccHuc7nyumBCiM4D6UsppvlYkhBglhEgRQqRkZGSoMDQiIiIiIiIiIgqE5oWrhRARAN4B8IS/ZaWUk6SUyVLK5ISEBK2HRkRERERERERETmoEiQ4CqO/2ONH5nEscgLYAFggh0gB0BzCVxauJiIjCw6wtR3DsLGebExEREZmdGkGi1QCaCSEaCSHKAbgBwFTXi1LKM1LKGlLKJCllEoAVAEZIKVNU2DYRATiVlYcNB04bPQwiojIKCoswavIa3DBphdFDISIiIiI/FAeJpJQFAB4CMBPANgC/SCm3CCFeFUKMULp+IvLvus+WY+TEpUYPg4ioDOn8//6T2YaOg4iIiIj8i1JjJVLK6QCml3ruJS/L9lNjm0R0wa5j54weAhEREREREVmc5oWriYiIiIiIiIjI/BgkIiIiIiIiIiIiBomIyH6Wph7HAdY/ISIiIiIiCooqNYmIyDg5+YV+lykskiiSEtGR4REXvvmLlYgQwJ5xw40eChERERERkWWExxUjkY1d4aOr2eEz51FYJHHVJ8vQ7PkZOo7KeEXS/zJERERERER0ATOJiCxu+5FMj88fy8xBj3HzUDMuBscyc3UeFRGRg2TAloiIiMgymElEZFMns/IAgAEiIiIiIiIiCgiDRERERKQZIYweAREREREFikEiIiIiIiIiIiJikIiIiIiIiIiIiBgkIiKiIEkpMfafrdhw4LTRQyEiIiIiIhUxSERkQ7kFhfh+xf4yz6/bf8qA0eirsIitlLSWXyjxxZK9uObTZUYPhYiIiIiIVMQgEZENfTg3FZNX7Cvz/JUfL8Pe41kGjEg/eQVFRg+BiIiIyDLmbT+KTelnjB4GEZlElNEDICL1ncrO8/ra6ew8ABX1GwwRhTXJ5D4iIlP7zzcpAIC08cMNHgkRmQEziYiIiIiIiIiIiEEiIrKXcKi7RGQlQhg9AiIiCtSzUzbh4R/XGT0MIjIQg0RENpKVW2D0EAz335k7jB4CERERkeWMm7ENP67aj783HDJ6KERkIAaJiGyk2xtzAfDOPREREREF57OFe4weAhGZgCpBIiHEUCHEDiFEqhBitIfX7xNCbBJCrBdCLBFCtFZju0RU0jlnJlFYF4oN61+eyJqklHhj+jbsOppp9FCIiIiIwpriIJEQIhLARADDALQGcKOHINAPUsp2UsqOAN4E8I7S7RIRkXJHz+ZABhlYk2AgjtR19GwuJi3ag1u/XGX0UIiIiIjCmhqZRF0BpEop90gp8wD8BGCk+wJSyrNuDysCvMIg0srKPSfw/cr9Rg+DLGB3xjl0e2Muvli8N6T3C3BeI6mLAUgiIiIiY6kRJKoH4IDb43TncyUIIR4UQuyGI5PoEU8rEkKMEkKkCCFSMjIyVBgaUfi57Svfd+Kf/HUDcgsKdRoNmdn+k9kAgCWpxw0eCdmZe6La8t0nsDvjnHGDISIiIiKfdCtcLaWcKKVsAuAZAC94WWaSlDJZSpmckJCg19CIbCW3oMjn67szsjDhXxt3AGPVbtXsP5GNDQdOGz0MsgkhgBs/X4GBby80eihERKaUeiwTRUXMqCQiY6kRJDoIoL7b40Tnc978BOAKFbZLRCE6dOa80UMgg53OzsOdX6/2uUyfCfMxcuJSnUZEdsea8kRE3m1KP4NB7yzCpMXsMEZExlIjSLQaQDMhRCMhRDkANwCY6r6AEKKZ28PhAHapsF0iChEv1ij9FAOFZJyiIkc3swPOKY8u4bZvOpaZg9lbjxo9DCIygfRTjv3h+v2nddvmodPn8do/W3XbHhFZQ5TSFUgpC4QQDwGYCSASwFdSyi1CiFcBpEgppwJ4SAgxCEA+gFMAble6XSIiCo2UEsfP5Ro9DApjO45mYtKiPViaehzTHukdtrNEb5i0AnsyspD6+jBERepWAYCIwtyxszmIiY7E47+sx4o9J40eDhGZjOIgEQBIKacDmF7quZfcfn5Uje0QEZFyXy9Nw6u8c0gGcmUMFYZ57Y19J7L9L0REpLKub8xFXEwUWtaJM3ooRGRCvG1FRBRmFu9S1j0y3KYEkb4OnMzGF6zJQTo6fOY8TmblGT0MIl1l5hYYPQQiMilVMomIiCgMhekUIdLWbV+twt7jWbiiUz3UqBRj9HAoDPQYNw8AkDZ+uMEjIdLeOQaHiMgPZhIREYW5cK0HQ+YjAWTm5Dt+ZsYaEZHqHv95ffHPq9NOGTcQIjItBomIwpBWF1+Nnp2GJ3/doM3KichSpJR47o9NSNnHoqhkDUmjp+HQaXZ+JHvbezzL6CEQkckxSEREqpES+G1NuqFjSOPJj1+lY4TM2CAtFBRJ/LByP276fCWAkhlrrp+3H8nEHV+vuvC8ngM0Ackvn+lsPngGAFBQWISk0dPw+SLWxwrEqr0n8feGQ0YPw9K4NyAis2CQiCgMSQ1ORZQWQ1bLmfP5Rg/B9E6xQCsZwFs8ZMEOc+w7jCQ459N0cgqKAADvzdlp8Eis4brPluPhH9cZPQxb0HJ3sGDHMew6dk67DRCRLTBIRBSGZm45ivUHTqu2vmNnc3Drl6v8L0iGOpOdj2+W7sXZHBatJCLyZsuhM/hz3UEAQKGUvPlAlrHvRBbO5nj/vE5evk/H0RCRVTFIRBSmrpi4VLV1nc8vVG1dpJ3RUzZizN9by9QjYBID6aGg6EIqkbesIlniZ06+IGMM/2AJXvhzMwAgJ78IHV6ZVVxQncjM+k5YgCtVPL8jovDEIBERURjYk3EOMzYfCem9vItOWhM+HhGZQSYzMMkidmewNiMRKcMgEREpxtqr5nfv5DVeX/P379fhlVn4a/3BMs/zUp5CNWWt/wL3H8/frcNIiEpifSii4Gw/chab0s8YPQwiUhGDREQm8cXiPRjx0RKjh0F+FBVJTJyfGnZTD5amHjd6CGQjvlswO6KW3yxL02UsRnLNwDt4im3XzYId55Q5fOY8s0/DzND3FuNynr8S2QqDREQmMXbaNmy06J0YtW68vjVzB578dQMOnjbvBdOsrUcxYeYOvD5tm9FDUQ1vnBMZa8bmw0YPgUgVPcbNQ/+3Fhg9DEsyW3wyz9nhj4jCD4NERBZmljueag3jo/mp+G1NOnqOn6fOCjWQW+Ao0p2Vx2LdRKGau/2Yx+dNskvTHQO15sHpZsqdzMozegiWZpaPYMa53KCWLygswth/tuJ4kO8jIvNhkIjIwopMekFVaNaBqcgsAbpAWWu0FHZMclGkphmbDhcHlck6vlyyx+ghWMr5vELM3FK2KYLVjpHhQssA1MKdGfhiyV688Mdm7TZCRLpgkIjIwpQe68+rkA2zZt9J9CuVWt75tdlBr2faRmtMt3DdZbbS6e/qtJNIPXZOtfXx3J+0Zf2I0fLdJ3D/92sxbvp2o4dCQVqx56TRQ7CUF/7c7LExwrgZ/OybUTDH72D3xK77gwVFnKZGZHUMEhGFMTWKL8/aerTMc6EUrXzwh7UlHieNnlbicVZuAc5kG18M04qXr/d8l6J4HX+uO4TNB0vWzDJLSjyZw7GzOViddhJnQ9mv+LlwyckvxNZDZ0MbmAFc+8BDJq6vRg7ZeWxtr8SBk9ken/9maZq+AyHV8RhPFL4YJCKikM3ffgyfLdQuNf/AyWykHsuElBLd3piLDq/O8rn80bM5mo2ljDDLpskrLMJlHzq6lxQxlYhK+Wv9QXR9Yy6u/XQ57v9f2ayCQB0/l+uxnsWTv27ApR8sxinWOiGVPTtlU9Dv2ZR+BidYdwUAIMPtYGhxwQR+TpzLQ5HJygeMm7ENT/yyofjxwp0ZeGfWDgNHRGRPDBIRWZjSQ3co7z9xLhensx0XavcpuBgMRO8352PQO4vw7bI0nMv1f7f3qo+XaToewPMJ1qq9J/HPxkOab9ssvlqyFwCQk8+UcnJYtffCFJ0tGmT8rNl3CgBwPt+eNX6EJXMU7WHX0eCn4l7+0RL0nbBA/cFQWJm15YjumWxztnluGuDJZR8uwUfzU4Pehpb3kT5buAe/r00vfnz7V6vwwbxUpB7LxLuzd7IWFpFKVAkSCSGGCiF2CCFShRCjPbz+uBBiqxBioxBirhCioRrbJbKLtftPGbLd71fsC3rKWZexc9DxVf81h/adyAp1WGVsLDXNyZuDGk/tWLv/FP7dXLJA58b007jus+V46Id1mm7bTLYets60H9Lf6ex8PPnrBv8LBoBdcsisArlxYWc5+YVIGj0Nq9OMOX+xum2Hz2LU5DV43uRFnufvCDyo9O7snRqOpKTVaSfxy+oDxY9vmLQS78/dhbPnw/t7SaQWxUEiIUQkgIkAhgFoDeBGIUTrUoutA5AspWwP4DcAbyrdLpGdfLssrfjnkOp5hOiDeal46a8tIb/f1/2aI2dUnPplkhtDV328DP+4FdjefPAMRny01MARqSPYHAbeqCN/fluT7n8hd14+hMlj5wDgZ46Md/H4ebj729VGD8M0TpugRqCVuYKM7jWdrD51z3UDqVCHHfa1ny7H079vLH6cx06SRKpSI5OoK4BUKeUeKWUegJ8AjHRfQEo5X0rp2guuAJCownaJbOmTBbt13d7JEGt8DHx7gc/X1TxFmLLuoIprC3Lba9PR5bXZKCw1L19CqhsIM1Cw/1bL95zQZBxkL8HsW8ZMDT1YbUUHTmbjr/XG7dfMKmn0tJBqBIVq/vZjQWVGlp6qs+VQYFmu4ezEuVzM3x54Nko42nU0E+sPnC5+bPXppwt2ZBi2basH2ojMQo0gUT0AB9wepzuf8+YuADM8vSCEGCWESBFCpGRkGLeDITKSrsWXFdidkeXzNMYud/5f/HMzTmTl2bYWSijyCsxbi2jn0Uws3Mnjhxl0e2NuwMtO33TE5+tW7bLjbTd45cfL8OhP6/UcimX8uGo/kkZPwzs6TF258xtlmUEfzUvFCgbNPcorLMLS1OPoMnYO7vxmNbvI+XDJu4twxUTrZyWbSVGRxKcLd+uanU9kJ7oWrhZC3AIgGcAET69LKSdJKZOllMkJCQl6Do3INKasDfzustEF+nJ9BAskJIqKJK6YuBSztx71ulxWbkGZdvf+rD9wGpNX7AvqPaHKynMEh0r/raU074Xruv2nQs4Qs7rB7y7C7V+tMnoYhsvJL0TjZ6fZIlvF1U4+UOfzjA/ouvYNWw+dxS1frERuqakQpWstmXVfoqfS+9gP5u4yaCS+uU+lnLH5CG6YtMLA0ZjbzV+sLP7ZZE2yTOnrpWlGD8HyXFlYC3Yew/gZ2/Hq31sNHhGRNakRJDoIoL7b40TncyUIIQYBeB7ACCklK1EShYGcgkKsP3Aa93yXgmW7j3tc5u5vU4Je7xUTl+LFP/Ut9ujevcnsrvx4Ga76+MJdSX+xRD2vT3MLCjFxfqqps5HsICMzF0USmDDT+q2Bg6kD8+/mI2j10r/YlG6OaUAHT5/HktTjmnR8s5tgbpAYSa2i7ESl2b2Lox5OZufhw7m7iruvnsthBhtRKNQIEq0G0EwI0UgIUQ7ADQCmui8ghOgE4DM4AkScmExkIavTTuKZ3zYqzlq66fOVZer6bDhwOuj6NhvTTwe87IiPlgS1bk/iY6MAAHeVCmZpnUk0fsZ2DHt/ccjvTzuR7X+hELmfwOYXBh7sOXT6PMb+sw0TZu4oUaydlPt66V6Pn5e8giJkZFr7vszmg2cDnr7qmmq48eBp7QbkR0FhUZmg0M4jmQaNxjo2s74PhRFf+7R5rOEUNOE8IXvm9414e/ZOrHSeW7JGEVFoFAeJpJQFAB4CMBPANgC/SCm3CCFeFUKMcC42AUAlAL8KIdYLIaZ6WR0Rmcz1ny3HzykHVEkVd89uee2frRgZwhx8b93ENh8se4Gx0STZBKH4dOFubFOp1by/YJaSf9pT2YFPa7t4/LziaYKvT9+GO79ehRmbDrNWhQpe+Xurx8/LscxcXPT6HANGZIxFziBR2vEsw8bw9uydZaZKjZ6yCX8aWIDfCvScaiOl1DXbbNKi3Zi99SjembXD8GniauEUydAdOZODDc5C1SnO7CFSh+t8It/tpHX57hNhOwWfKFSq1CSSUk6XUjaXUjaRUr7ufO4lKeVU58+DpJS1pJQdnf+N8L1GIrK62VuPlunQscF5Ur7raCa+XLJX8Tae+nVD8YH/sg+VZw3Z0V/rD5q2VfH8HRm4//u1eOGPslMHs/MKynSPu2LiUgx6Z6Few7OsY5k52OQhaGpVwdwJPnj6PABg7f7TGo3GP2/Bh+W7WeDYLCav2IfLVcg09WffiSzM2XoUb0zfjnu+S8EH81KLW59bXZZNfg81nMnOxx1fr8KxzMAaj/R7az5en75N41GpwxXTzMzJx1szd6AgiOxhI7jOO91jsTd+vgI3fc7aYUTB0LVwNRGZz8KdGXjoh7V+lwv27ufXS9O81p255N1FQa3Lm1/XpOOtWeapuZI0ehr+3XzY6GGUoHUHpQ0HlAcj0k+dLzNt7frPVqD7uJLdsdYfOI3UY+cUb8+qpJT4a/1BvyfpA99aiAe+9/+dtjOrJTmcDbI4Nymz7bC60/+SRk/D3G1Hi4usbz54BpNX7EPfCQtw93fB190zu/N5hRjwdnABe7tkUHnyS8oBLNiRgUkL9wS0vKtejhVk5uRj1d6TmDBzBz6an4q/1h8yekgBcWW6uT522znllygoDBIRWZhap1z/bNQmsNHh1Vllnivd1ceqth056zEz4JMFuw0YjTK5Ck5Y1fj3XJV2Es2en1EiUOTKhBn0zkLdOtmZ3dQNh/DoT+vx2SLfFyKZvMOPCIvNhflwfqrRQzCl9+bsNHoIAbvr25TizoqXfbhE9+YKerJLNpRaigMSxg5DE7szsnDdZ8txwpm1XVBkjQCXjWOSRLpgkIjIBKxyZ0YNyWPtUR9l34lsfL5Y+ZQ5M9idEXp2jntg52yOsmwIT0WwU4+ds/XFVjBcUyuPnQ1sSoNdhHTX3VoxorDnLcvkvTm7PD6vlFYxxPXOOjN2p8bfb+qGQ2Vqd1ldkY0jE8FOM3NN/TWaff9FiLTFIBFRiI5l5uCQSQ6CWhIWuyOvtrNBtk810wlJ0uhpAS2nZMxj/3HUVdh2+Czaj5mFP9alh7yuzJwCnM8r9HhyOZ/dXoqF43fyiDMwFuivvmrvSQCO4IPeWQ+hdNMJv3/Rklxd6fSQk1+IHLYYV0Tp5/X3Nel45Md1eGe2dTLFrK6wSAZcM0kNv6WEfi6gJve4XfqpbGQqvJlFFC4YJCIKUdfX5+Li8fOMHoZuzBT8cLd+/2lsMVHr5I3pZ8LqAiTPeXfR1Vlr0c7jIa+r2xtz0eqlf9HTw/fqzm9Wh7xeu/B2k9o9GPjL6gM6jaYkveJWwd6on7RoD9q+PBNHTZB95etvpEb3SCvTMgNn5Z4TOJ93YZ/c5bXZmLJWu05z3y1P8/m6t1p94eSJXzcYPQRVuQL3aiYSFam8U5gwcwe6vj7X/4JeBPu7vWvCqaK9/jsfl7PJCVFAGCSisJKTX8iOHArM237U6CGUsfXwWQz/QJuD/jWfLAvpfXsyjGu/HYpwz2Iwo0U7M7AjhEKbT/++UYPR+GfWWRbTNx8BAF2zPpem+u5itjH9tD4DsRA1p5V9uWQvXvtnKwDgwMlsXD9pBUZP2YjzeYV46tcNyMrTNoj/0l9bfL7exUJTrvdknEPS6GlYsqtk8F9JNqMdC1hrcQy9//s1QWf+7Dvh/dxj7jbznb/po+TnLe1EtkHjILIWBokorPQcPw9tXp5p9DBUo+e5lpTA0bP2KDodqJR9p4wegulM06jIOZV021erMOS9kl0A7XdpFTylf4Pj53Jx+Iwx04R/Wn0Ai3ZmYGO6eTIftdT7zXlIGj0NS1NDzy4MxWv/bMWXSxz14jKd04V3HMnEr2sO4Nc15pgCYxWr0xzTNv9ar17m1R/rtMvispOZW47imd+CC/r3nbDA62tKsz23HTmrbAUa8/b72TAmSaQLBokobGTnFRR3Z7j1y5W2mBLUVoeAl/txNzIMa6GEIpSaJEYK5ruw2cvUPl8nYlJKBpdClDR6GnILSv77uL6Gp7Pz8M6sHQaMypy2+7iI2Z2RhYU7M5A8dg56jDNumvBtzu5X4eDASUcw7uYvVhqy/ZNZecXflf0ns7EpTIJzahLOM4CTWXnFhfMB4P7/rQl5nSfO5flfyGIutFtX99ifF2SxaC25vs9md+E01VrnYURmwyAR2Z6UEmfO56P1SxcCKot3HUfLF//FbyreVXz176249Ut9T4b1PIGQkIiIYJDIjs7mFGD6psCCOLuPBd8Jbe62Y3jwh7VBv48czp53ZEOUvgAZM3ULPphnjtbpZogfD31vsdfXnvx1Q3F7cgC4d3KKHkPy6AV269NF59dm42lnJkZ2XiGziBSYu/0YOr82u/jxSmdheHJw7f72HM/yOeUrWMyCueCfjYcCbsYBAD+uctTnc/0JzXCMIrISBonI9iav2IcOr8zy+NqTKhZP/GrpXizepW9avd6iLB4kWrLruO6djqxiXoDdw2ZtLVvXYPnuEz5PwE5mq3vneODbC4prjoQj1939bI1rqwRDr4uZYO7Ut37pX6+dbGZuCdf6HOFl00FmDymi4iH/u+X7PD5vhqLySpzLLSjOslq867jPKV/BUnO/KixeffDXELul2bEGFpEeGCQi2+P8d3VICUtnEh09m4NbvlyJ//tpndFDMSXXv+zS1ONIGj0NnyzYHfB7b/x8ha53PHdnZBXXHPFmzb5TaPvyTMzacgRP/rrBEieK/2w8hMs/XBLw3dJgfqNTWfab4uFPdl6hpYrI61lcW2ulv287jmTi59X7DRoNqUVJPa8JMz1PjV1r8dp/l7yz0GNG59LU49iTEXzmrbuCIvNMN7Mq8x/5icyJQSKyPX9hjQITzfk2I/cMEeuGiFDcAnlXCNOlgmWBeIRXf284BAD477/bQ3q/np+R3IJCr5kinyxIxbncAoyavAa/rUnHH+sOYsGOwLKljHDo9Hk89MO6oDIfZnvI6vLm/bnqdY8yUq//zseZbM//5lZ38XjjaiWprXQdoiHvLcIzv2+y7b+dXZXen/cYN09RbadOr87C69O3lXjOwodLAMDhM2UzofafyMbNX6zEgLcXKlr36jRrB9AO2ijwTRRuGCSisNf0+RlBv+fEufDo8vXv5sPIL7xwCvdxENklZhVoACc7L7ympak1X1/PE/4rJi5DuzGep5KW7iD1+C8bcMfXq/UYVkjyAwhWuz67etZW+GHlfvSdMN/vcnqOKTUjU7dtTVmbjj/XHcR3y9Ow66h+27W6ZbtPeHw+v1RmxG9r0jHioyV6DMm2cvILdT1e7Tke+o2WUx6ChMcsPt3Mkz4B7DP1ptoxPoiDfM/x83Tfb5Y+9i/YkaHr9onsIsroARBpTQRwZDyZlYdjmTloWTs+oHW+Md17lsXsrUdxSetaAY/PzB764cLUrB1HMrHtsLlboPpS3H0kgDDGH+vS8djP6tWrCgdGFIX09Xk8lmmtQG5EAH9A12dXzz/1c39sCmg5PbPnSm9r6HuLsP2INhcij/9yYT8QFSGQ+salmmwnXGw/nIlbvpyDYW1r4+ObO6taFzBc9X9rAQ6fyUHa+OGqrvfwmfPYqcMF/pi/t+KOno00345RZm45giFtahs6his/XqrZPtJfd9QDp7LRrFacJtsmIu0wk4gIji4oQ99bjLyCwKaeFfm4IrJyIKW0gqILv6eZWrGGwlW08cDJ82jjo6At4OjGFW5cf59QL/Z9vc/K0xT18O2yNPR+03x3ns2q9EdNq4uf0tz3h+TdO7M8154BgFucHUBnbD6CJs9ND2h9Vi9s7MluZ62aIhU+U56mO6mhx7h5+Hyx79pv5N+9k9cgy61hxlkf5x5aWbf/tGbrfvmvLZqtOxinOZWVSFUMEhG5af5C8FPPwsXSVPt0bsvKK8QOnS4srcKVyLL/ZLay9agwlnDz8lTtT7K/WZaG6ZsOa7Z+PTPJrFzzKxx4KuLrSaDxkW5vzFUwGnP6adV+7DuRhcbPTcdUZx04q1BSkyhcnc8vLA4ItvcyRdqqfk45YPQQiEgDDBKR7Wl97VK6i4tdL2Cs1CXInSs7rPRFrJb/TLkF5mlNHqhgpuORMZTWJHr4R3t09rNCp7pQJY2e5nf6hpkZse/bfuQsksfOwXEL1Qr8fPHe4gy4vy0WJPrCT2dJKit57JyQm0GY2ddL+VkgsisGiYhC4H6RUrrm0cwtR2x5EVNo0akWY/52ZGm8M3tnief/3XzE63uU/qZXf7Jc4RqMk51nvQvUZbvtk+UWiEDqrHmi5X5J15pE+m3KECey8oweQsiem7JZ921OWrQHx8/lYsGODHy/cp/u2w9VpPN7bNVjKwXn1zXpRg9Bda/8vdXoIRCRRlQJEgkhhgohdgghUoUQoz283kcIsVYIUSCEuEaNbRIFSutpED+t2l/i8dbDZ/HHuoPabtQA3RtXM3oIIVnjbCFb+t/kS94NLaGwSGLv8awynUGsYHcQWW5WztJwOW/BQJ6abBiDtw2jpyU//4f+QSqzCPf9AlGgHv5xHZ4PsCkDUbhSHCQSQkQCmAhgGIDWAG4UQrQutdh+AHcA+EHp9ojMZvSUsgcapZ2VjD7ZKyqSGFOqTkpCXKxBozFAGF6Eph47Z+kW3zM2HcbKPZ7bbrt79R/z3fkMNJC95ZCjKP7kFaFlS6j1sc7OK8CGA6dLPKdrTSKdvqBHNCoI7I8dM1H1EO5/t1GTU4weAvkgpUS+xRuA2MXfGw7h+5X7/S9IFMbUyCTqCiBVSrlHSpkH4CcAI90XkFKmSSk3AuDekWwh1OkegXJ1PjHKvpPZ+GZZmqFjUMuOo5nYmH7a42upxzz/ndW4CFWjaw0F7v7v1+L6SSv8Lrfby7+5mbk+jycVTkNScg39o1vGZOuXZmLkxKVYssuYrJHVe0/psp3u4+xXMFlregYLi7cJa0/bUutPtliF7+Of6w5i7f5TmL31qAojUsdjP683Ze2bnPxCvPBncNkogXbQtRPBdhZElqRGkKgeAPfS9unO54gMVVBYZNiFOg+J5jLio6Uenx/0zkKPz4fjDWkhhGb5GVoHVY2mV0vjPAPvQk9eXjZ7afuRswaMBJi8Ik2V9azZp0+wifRhtRsbp8+br2X3//28Hld9vAz3fGeerKQ/1h3EK39vxQGFnTfVNn3TYfxvhbmzUQoKi/Dd8jRDx2DV4C1RuDNV4WohxCghRIoQIiUjI8Po4ZDFNX1+Bu7+LkWTuxil09pL3+EvsOVB0Y6/k3ay8gqMHkJQ7B3G0c4f69LRfswsbDscesDE79/e+dWLjY4MeRuhWLPvpK7b09smLxmGa/efwot/eq5tM+DtBYZneprZYYOm6AHA6WzzBV18efLXDUYPAftPZGPK2nTsP2GuAIwnZgpcAUBkRHBHzVPZ+brvO75bvg8v/bXF/4JBWLQruOuzg6fPq7p9ItKHGkGigwDquz1OdD4XNCnlJCllspQyOSEhQYWhUbiau82RKj1v+zFdttf/rQUlHn88P1WX7WolnAIGj3hoC65GJtG4GdZqd6tWss+UdQf1rw0SxPbUTmpauMNxwqwkq8ZfppXrtxvapjYA4IqOdUPeVjCW7y5b48lb4e9NB/XLKjp+Lg/ZKgRhP16wGyfO5eKxn9cXry+3oBBXfbzMa92nPRlZ+GLxHq/rVKMwejhmMvqzyYIF9QNl5D93nwnz8fgvG9BnwnzTF/XXK5Nyx5FM7AkgmBMTFXzQ3ltWs1a0yHKdvsl7Z1hPzJJIbJJhEFmGGkGi1QCaCSEaCSHKAbgBwFQV1ksUsu1H9C3Ae6ZU2niWwsLTZrxIWLHHnlkFUzccKvPc6fPKW1Bn5Vork2jHkUxFFwnuH9mzORd+9/zCIqSkmeezo2d9hO+Wp2Gyn1T/ifNT/abju/YHrpNtvTOK3LlnTbqCWwt3ZpQpZK21R39ar8p63pm9E3+sO4jfne2pXwugsLm3oF7qsUy0fPFfVcZlRf9sLLsvVcvlHy3RbN3k8L8QC+JbWWGRRPqpkllUQ95bhAFve56K7i4m2lSTMUzLW+1HvdkywZ9IQ4r3cFLKAgAPAZgJYBuAX6SUW4QQrwohRgCAEOIiIUQ6gGsBfCaEUDf3kaiUCLeT+PMmvztmRp6ugUoHwuzq0OnzqgTE/lqv3QWTFs7mFODThd4zJILidjL21swd+Gn1Ae/LqsEEtyo9BXZf+msLXvST6j9h5g6/616594QhHQ89fefdf03XX33fiSxdxuNu3f7TitchUfaj4+og54u3WSaeMq9CYcUaHlJKPPRD2axMPbj+DfXqeqc24/deDr85A6Xh5KN5qej13/l4b87OoL+/UUFON7OTYG78fOehnh0RmZ8qYXAp5XQpZXMpZRMp5evO516SUk51/rxaSpkopawopawupWyjxnaJvIl0+2RvOqhemvrZnHws2XUcG2yc+h7OzmTnI82AC95gLNhxDJk+UsiVBPOU1NUZP2Obx+d1yeozMPXOlVXiawh3f5uiqOjqoz+tR+8355XYxmodsrP2+xlz8cW5AX/+6EjHxtcrzGByZZZJOLLeAgk+ectGO5aZq2gsVpZrgq5N7KIUmKIiiaWpx3E6u2TGrN4Z2GrYdvgsDp8JvebNyr2OwNB7c3bhxs/9d8d0F2GCmxNGuebT5UYPgYg0xlxJsiUlB++9x70HCR78fi1u+XKlz2XUYPQdUU8n27rXmTFAh1dneaxRFKpPFuxWbV2AI8vpjq9X47Gf13tdpsMrs1TdZqCOn7twweH++bX7ebTr1/P17Ziz7SjG/6usRtXxc3nFf1chgBsmBXdB45I0ehqOZQZfXHjn0UzkFRRh3rYLrbF/1jpDzIfCIgkpJa6YGHqND4GSga7/BlhHzNtn2v07YCQpJSbOT8WJc/oFrf7ZeFi3bXlz5KxxRbOVmLv9WNCt1JX4aule3PzFSnR8dbZu2/Qn1GPlsPcXo8e4eSG995fVB7BMQfaf3Y9tRBTeGCQiW1LScvusj0yMHRa800bBUfNC778KAwOlZTunHM3Zpk9B9lC5xxPNdh6tdgDWta85nZ2Hoz4uUvNVzLT4Y91BRVOSQtmPFRRJvD1rR4npc0ZmHhzLzMWXS/YqWod7N6xDp8/jiwDX5+0mxI+rzNEOe9Xek5gwcwee+V1Z4GHzwTOYt/2o/wUB/O2htptezLaPCYWerdT9ZQgaQe1jZSCe/n2j7tskczmZlRdQkXKicMQgEdnO7K1HAyo+Ggo9c2nu+mY1+k6Yr+MWfdOrs4hRwiFTSi/TN1/IKtDlr2rgLV3XpsdO24Zub8z1utysrUeRPFbZnXtXUCMn35jv4j6Ttcl+b84uRe/PKywqDjCYIRPGRel3psAZQPTWAW7xrgzM3+E70Lwp/Qwu+3AJ/vNNYG3Hi7j/tAw7TJMqLJKaNIdYu/9U4AvzI295/d9aEFCRcqJwxCAR2c493wV2UuuNGc6fpHSkoOt5UZY0eprPu8HBtj21Gitc4yzfcyE1Pmn0NHy2UN3pbGo5cPJCjQg9/q67g+iesmLPSSzcmaHatoOpXerKUssvLMLRsznYHeQdzHM6d8zbcKBk7bWcAnM1AVDj77EqzXFRePB04HVNhICiOij+zN6q7b721i9X4c6vV2PNvgt1rXLyC5GZk48jZ3KQNHpaUN3ECoskFu86rsVQSQNmOMdR6uWpm9Hm5Zmqr/eqj5cFvKzZ68vvP5GNr5emabb+YDJS/91sniC8u3BpyEIUCgaJyFa0bjtuZCDh6Nkcn9NZ1PCwivV4rGTHkUwUWiBK9OKfm0s8HhdgDRW9uU/p0iPD4JtlaUEt/+7snapte9vh4Kdc9X9rAbq9MRcDTX4Hs3SNlwU7PAfX8kxQtDhUoRRr/3ppGnqMm4eUtJOa7JPfmK7P9/rqT5YXZ1AOemch2o2Zhe7jvGfDeZOrU/DwuI41lqxqfwA3luxQ4Lv09Lyx/2zFWR8NHbRg9uy5m75YoWkQZMh7iwJedsrag4q3p/X5PRGVxCAR2crNX6zUdP1GTUk6lZWHbm/MLZ7OUlBYhHwNp3/Z4U5jMIa8t8iSbafNyv1rYvLzaMWC7Z749qwdSD8VWhbKij3qtFhPPXYOG9NPq7IuADifb64Mo2Bc1akeACCxavmg33vNp8t9TjG0gtyCIszcciTkzyQALFIxM8+X5LFzPD6/Yq863ws7CCRQYsfj+xdL9uKdWeoF//2Zvukw3pjuuaOnWSj5Tqtty6HQO6e62PFzS2RmUUYPgEhNStshA77vsul1vVt6O7d+dSH49dJfmzF761HNs4rCTQGDRKopKtI3k8hKPpyXGvJ7A2nPHohX/nbUbEsbP1zxuhbuzLB0kCgmOhKAuS6olArmK9fyxX/9LvP7mnRc3SXR6+s/rDKuyx0AnM7ilJFg2PVaO7egELszziGvoAit6sTj/Tm7sO9EFt65vqPq23rg+7Wqr9POgpnOS0TmwCARURD0uuB1b+u87fBZbD544S7Md8v36TIGMpeVKmWR6MH9WxKOQaLtR86GTSfE279aZfQQFAm2LpTV5BUUoVyUsqTxJ37dgEYJFdG5QVWPrxcY3dTArlGPEASyu40IppCahQghiqfwrn5+EN6d48gsKh0kyszJx3iTTtUm73gfj0hfnG5GVMpva7zfFVX7eje/sAh/rEv3ucyw9xeru1E/1gXT3cNGdh0190X9a9O06dinhSNnLmS5FVm3XI1fnup/PDtlI4a+txiP/rRe/wFR0FbtPel/IYtatvsEmr8wAxmZF2r5BNrSvrRzOd7rgRQU6nf1tmx32QLZehd018rd3zqabny2cDf+XBdaDZdAgvJmDRFtOHAa42Zsw+q00L6T7r/XRa9fmJr4S8oBzNpyBN+vdNxg6/PmfHy/cj/88VReICe/0O85G2mDHWiJ9MUgEVEp3y7f57VAZjAHqT0B3KH+dMFuPPbzhoDXqYcrP14WlnO/rwyiq0kwnvx1gyr1o9yzyczuWKZbkMiEJ3ZqjajPhPllnvvR4Kk3pD8tO52pYfqmw9h7PAtbDp0JuKV9ad4K++fkF2JViBf1oZi//ViZ50y4iwnJnG1HkTR6GsbN2I7/+3l9SOsYOXEpJq/wk21s0uP7yIlL8dnCPbj20+UhvX/GZs9dAZ/+bSNGTV6D5//YjOy8AogAT3A8Za60fPFf052zhQtmEhHpi0EiIg+8dYQI5mR0wNsLMW3jYZ8BggOn9GtxT8b4bU16UF1APHEPupS204QZUO4nc2YMEm04cLpE3SQiJbToRqbmXfOXp25B/7cWKNpX3Pn1amw/UjZQrXctp88X7w3oBowdhBp8LN0F0zako97d1Z94vqFzMivP7ypavzQzoOUAoMCZBnvkTA6y8+yRrWZFh06fx8iPlrC7IZHOGCQi8mDNPs9TroI9bX/wh7U+O2D8ksK05XCwJyMr5PcePZuDrq9776A0+N1FOHDSXMHGwhKFqw0ciA/5dp4HF6C520KbekQl/b3hkOrrDGQ6TLC2KMxGHPrehanPmTn5+GNdOga9s1DpsII24O2F+GmV+n8fs+kxbh7yCkLbT/kKpEVYIFX4hIeAwJ7jWcgtKPJ6fqa2+duPYfqmw+g+bi76TliAn1fb/zNnRhePn4cN6Wds1VyAyAoYJCLyYPqmwx6fD+Xu7tdL0xSORn8mTP6wvFAzV9zriXjT+8352HzwDGZt8Zxur7etbu1uzVpHINgY0eaDZ2xX5Piub0ObekRlJY2epur6ftQgCLJdYTH1yuWjAQDfLktDuzGzDJ12M3rKpuL6RBaIeYTMVxapLwPeXoiLx3m+uWCFP9cHc3d5fF7PzNT7/re2uItZRmYunvl9k27bJiIyGoNERB4s2VW2OCYAZOWF1upZ7QsIrfV+s2ytFVImL8S6RCsDLKx72YdLMGrympC2oTbX73rmfD42pJ8xeDSeBZtJdNmHSzDw7YVIGj0N1366DGdzrN92OzaapwBmteXQWWSFWJDZ24X0klTPx7VAnTmfj+9X7sPLU7coWo9abvp8JQBrBD1CtevYuZC7xx06UzbAlFdQFPB0KyPle7mpcsuXK3UeifHM3lQjUDn5oZ0/68FTQXyicMczRCIPCjSYI2PWjArSR26I0wZe+8c6Xc3cTd90GB1emWX0MLzKD/HfAwBWp53StaOTVq5Lrm/0EMiHvcdDm6Z6Klu7IMDzf5ir3k3S6GmmndKqhju/Xo2nf9sY8vsveWchNh+8EKi/85tV+Gm1+YvrewuMrdt/Wt+BmECo5w5ms89DN1B/9DpvdgWciegCBomIdJKTb48DPYXmsg8X49tlaWFT18CVpm9WOQpPvMdaNHjnjnFrczsf4p13/rvay5R1B0N+765j53DZh0tww6TlyMotwNLUEyqOTDus13jBUwqChGby6j/BZyDaOQBMZHYMEhHpxA7TUyh0B06ex8tTt7CugUm4Ut+3HDqDjMzcElNMp244hBS3tt7ud+JdlFy4mYUMuhQ/6WmvgoL3ZC9jpm5RlFWxYs9JLNqZoeKISC/bDisrOG8WoQQoC3WMEo2fsd1nN2KicBNl9ACI1KJ2K/CiIomICPWqHRw/l4uESjGqrpOsqbBIIpKfA0MNfLtsV6Y9b1yKiAiBR35cBwCY9kgvtKlbGZd9uETv4ekiN78I+YVFiI7k/SIzevr3jbjuouCnBDL4Zz/fLEvDQwOaokalmJDXcb/Jszs9CbW7m92czMpDtYrljB6G7vQsVP7pwt1oWTsOV3Sqp9s2icyMZ4ZkC7szzmHwu4tUXefPKerO2x/+wRK8Ns36U1RIudMa1gyh0DV+bnqJIvPDP1iCHQo7QpnZr2vS0ez5Gfh66V4cOxtaFyXSVrBdEaWUQXfuI2s4cDL4mi5WljR6Gpq/MMPoYZhC59dmGz0EVZw5H1xGvZ5BIgD4auleXbdHZGaqBImEEEOFEDuEEKlCiNEeXo8RQvzsfH2lECJJje0SAcCxszkeswKUenbKJtzx9SpIKTF+xnYcPH1e8Tq/XpqGpNHTkDR6GhbsOKbCKMmK/BWWPX7Of9t70seQ99QNPpvRK39vRdc35iJp9DTcOzkFADBv+1GDR0WAI3DprcvZsbM5ZaYgvTVrB5741bjW9KSdKz9ehvfnOFrD7zyaibQQC5uTNSWNnoYTznODX1IOoKhI4uW/NuO3NenF55Vm1+GVWZi64VDAywcbVFJqY/oZPPXrBkzfdBhLPXSDzMkvxLkQu06aTW5BIW9Ykk9CaeV4IUQkgJ0ALgGQDmA1gBullFvdlnkAQHsp5X1CiBsAXCmlvN7XepOTk2VKSoqisZnB+3N24d05O72+Xjs+FkdK3cF99/oOeOznsid51yfXx88pB/DhjZ3wsHM6RNOalZB67BzGXtEWPZpUx8C3F6JcVERxiu5/r26HZ37fhCYJFXFj1wYYO20b/nywJ6SUuP2rVZj6UC/M2noEEUKge+PquOzDJbi3T2Ncd1F93PblKnxz50XYezwLC3dm4NWRbTF+xjYkVq2A4e3rYPLyfRjRsS72ncjCop3HMWZEG2w+eAbHz+WiQbUKGDttG+7q1QhNa1bC8A+W4PPbuuDNf3dgy6EzWP/SYPywylHA96rO9fDl4r14oH9TLNqVgb/XH8Kb17THzV+sxG09kjCwVU1M23gYw9vXwaaDZzBt42G0qRtfXMxvRIe6QR10iIz2yMBmSD+VjaIiiQGtauHVv7fih3u64b05OzF90xGjh0dEJte/RQLm73DUmLmxawP8uCo8CuIT0KJWHHbYpC06hbdmNSth17FzKB8diYoxkTh+Lg/XdEnEb2usV7j81/t64L05O7E09QRSXhiEu75ZjWeGtkRMdAR2H8vCVZ3rYfOhs1i++wTu6tUIf60/iDqVy6NN3Xhc/eky/HB3dxw6cx6b0s/glu4N8fvadDStWQlt61bGH+vSMaJDPSzelYEjZ3NwXXJ9nMstwHfL96FelVhMmLkTzwxtgfaJVTDkvUW4v18TfLZwN4okcG2XRPyqwd9z66tDECHCt2xCVIRAlA2m6gsh1kgpkz2+pkKQqAeAMVLKIc7HzwKAlHKc2zIzncssF0JEATgCIEH62LhdgkRWiOwTERERERERkW9PDWmBB/s3NXoYivkKEqlRuLoeAPfiLekAunlbRkpZIIQ4A6A6gBK5fEKIUQBGAUCDBg1UGJrx5jzeB4Pesf90hVA0r1UJacez0TihIraXqvtRv1p5HDipfHoXERERERGRlTVJqIi42GisP3Da6KFgePs6aFM33uhhGKZbo+pGD0FzpupuJqWcBGAS4MgkMng4qmhaMw5p44dDSgkhBHLyC5GdV+izS4FrWVeilQjjdD5//t18BPf9b43m26lcPhotasVhlVtbbCW2vzYUXy7Ziwkzd6iyPrKet67tgGu6JHp87dYvV2LxrrLz4Ym09u1/umLZ7uNoUqMSnv59o9HDIae5T/TF+bxC1K1SHtUqlkN+YREe/mEdXr+yLao7O15l5RbgZFYe3py5A39zCrZtRUYIbB4zBBERjjqH42dsN3pIpKMvb0/G479swJnz+WhQrQL2W6ygeVxMFH5/4GI0rxVX5rX8wiLM2XoUw9rVMXwmRlL1Ckg7kY1/Hu6FSjFRmLH5CDJz8jF1wyGM6tMYt3ZviK2Hz6J1nXjLXaflFhRCSuB0dj66j5sLAFg2egBqxsVAApiyNh05+UW4/eKkEu87nZ2HijFR7IgaJjjdjGwhK7cA93yXgmW7T6i2zscGNccjA5uW2PkrPWh1qF8Fr41sg/aJVVRZH1lP1QrRePnyNj7brJ7LLUDbl2fqOCoKd6ufH4TK5aNRLurCyR/3T8ZbNnoA6lYpH9R7Coskmjw3XaMRkZHSxg8v85xdv6cvXtYaUkqMnbbN6KEY7olLmuPhgc08vtb8hRnIKyjCN3dehDu+Xq3zyIKz5ZUhqFAuMqigit6f70Y1KmL+k/103SaRUXxNN1MjFLgaQDMhRCMhRDkANwCYWmqZqQBud/58DYB5vgJERMGqGBOF7o3VTf17dFAz1e8OfH3HRcUBIjOrXy24ixIKXI1KMT4DRABQKcZUSZ5h4adR3fGfno1KPNc1qRreurYDejerYdCotNe6TjzevLo9EuJiSgSIyByCDRABgLXuaVOgKpSLNHoIutp1NBN3925s9DBMwVuACAB2jh2GtPHD0a9FTR1HFJqKMVGmzrpZ88IgBoiInBRfiThrDD0EYCaASABfSSm3CCFeBZAipZwK4EsAk4UQqQBOwhFIIjKtSbd2UX2dvZvVQJXy0aqvVwtREbxY1IrawUxSznV3vnvj6njp8taYvDwNC3cex/s3dETFmChc0yXRtnfrP7u1C+pXq2D0MMiDkR3rGj0EMokO9avgu/90Dem9X92RjP98Y73M/EY1Kho9BAozPPclukCV29VSyukAppd67iW3n3MAXKvGtoi8iVDx5kRiVXUvmmKjIzD5rtL13M1r7/Eso4dgKxNv6oxCKdG6ThwaVg+fE9/FT/dH7zfnGz0Mr+7t2xiXty97IX5rjyTc2iNJ/wEZIDY6vLITrCTUIJGJb9RTiLo1qobKIdxkKj097bv/dMVtX61Sa1iaurGbPRrYKPXwAOt3UFJizOWtMebvrbpsK7Ycg0RELpzTQLZx/FyeautS+yS7sIizK8NZm7rxSNLhruizw1pinEmKmO4YOxQxUeYOQDw7rFXAy74yog1enrpFw9Ho77WRbZAQF2P0MMiDWvExGNCyVkjvNfN0DgreS5e1xq09Gipax8SbOqNcVAQSq1pnKnkcp10DcHSRCmedG1bVfBt9mycgJ7/Q9OcsRHpiyJRso2oF7x3jgqV2mnN+IYNE4SxCp4u2e0xUv8FuJ1ulu3xsfmWIMQNRUbhkS1nR93dbJ/PUaHauGQYAQ9rWDrqbUO9mNfD6lW2LHw9vXweXtK6FihYJvHxxW7LXYGfVCvpN21/1/EAsfrq/btvzhNPutPf+DR3x8709jB4GkalY42hBFIBCFWuhcwoGqUmPGNFrI9sgQs05lwo8NaSF0UPQ1HOXtmRxcdIUs4ECV7Gcvb+L0SHs171Nb68VH6t0OLoY1Np7Fl2rOvGqdrL1pWac8X8vu9xw+efhXiG9T482R/Gx1qgXSqQnZhKRbfRtrv3dxFC6ft3SvQH+erCnBqPRVucGVYwegm0oDd484qOziUvf5ubpbNKsZiWjh+BTh8TKWPhUv5DfP6pPE/UGQ+SBmUNE7RMrGz2EYo1rVITda82y62BJn2rQWMSftPHD8eJlrQEAA1vWRPfG1XQfg9XVqBTa1OZ6OkyRNMsNNiIz4ZGHbKNLw2r4U+NgTCjThp4a3BId6ldRfzAa6tciAVMesF5gy6yUnn886idI9MLwVmhQ3VFs/Z7ejXwuq4cKJr+znxAXE3IB8fjYC7+b66KBSG1mziQaGGKtJC3Me7IfhKlDasoFO9XM7iponOmdNn44Ul4YhF/vKzn96LYeDfHmNe0x6bZkPDWkpaZjsKNQg7k1KsVg59hh6g6GiPzikYdsJdKEJ9ZWu8v5+/098MnN+t+pszOtaxINanXhoq1dYhVNt2UHjRNCy3T65ObOmPZI7+LHtyksJkv20LZevNFD0M2bV7fHQwOaYtOYwbi3r0lqoJnvsK8qtYNEVq/hFBUZUaZrm9pqVIrBRUkls4WiIyNwXXJ9RDLrJCRKzs+ZTUekP37ryFZMGCPyeULhnpXgbkgb4+7UJlWviPLl7DEH3iyUfi4jBNAkwXPmy2ODmpfonGbGQKnZhFrDZFi7OqhfrULx4yheLAAAVjw70OghGOqfh3v7XyhIan2yYqPVPc1rUrMiIiME4mKjg+oOqCW9GgMYJTpS3d/PW70is7uxawNMeeBio4cBAKhcPrxr2HQMITve7t9TIrsx95wAoiAVaVzhLpRDXJSPVKK/H+6FlLRTeOLXDSWeN3K6Dg/k6lP6NxVC4I8He6L9mFllXmteq2RWjBniFrXizd1WXUKd/YSZpwTppW29eNSubHxxV6XiY6NwNqfA6GEUU1pg+Pu7u2HzwTO4tUdDFBRJnMrKQ98JCxSt846Lk9CxvvbtqANxRce6uKePI5PJDPs8rcx9oi/3M07jrmqn2bqv7ZKIvi0SkFi1gv+FATStWQl3XJyEv9YfxKnsfM3GZVb39W2C+/63Jqj3xId5YI3IaphJRLaiRqv5Gy6q7/W1YNf+4Y2dfKbJNqxeEVd3SSzzfFM/hX/v69sEFTXK9mEBP/Wpkd0THxuNly8vWwNncJvaJR6b4YKiWa04o4dgiB6Nq6NGpXJGD0NXPZtYe+qKS6j7Pa12l0qzOXs2rYF7+zZBhXJRiI+NRsPqFTHn8b64qVuDkNc5ZkQbU0y1mfZIL7x3Qye0qesooG3XGxuVYqLQJMSpsRS4qAiBCdd2wGXt6waVITNmRJuwnQYVbBbtvX0am2LfQUSBYyYR2UpBYZHidQwpddGtxOUd6ob0Pn/nvKOHtcToYS3x7uydeH/urpC24U04HscjIwQKi7TLQotW6UTSU6Jc6ROv3RnnVNlWqGrGmTuLSCtzHu9bHNw9cDIbvd+cb/CI9PH0UHsUcA1lt/f+DR1Rr4r2nXfU0rRmJbx+RVscPHUeC3dmGD2ckLmCQy52PGQNb1cn5ML4gUxPq1axHE5m5YW0frtRMnXMrgFKf4IN+LgaaxCRdTBIRLaiyoW+SY75d1ychG+WpZV53v2iRIvzk3C82zO0bW3M3noUeQXKg4yehFK7Zub/9cHe4+eQkZlb/Jz7pzuxanmP3fxW7T0ZyhBVE653vt2z/9zrFtlZxXKRYbm/cBnZsZ7RQwiaEAINQ7hgG+HlhseXtyfjrm9TlA5LGRt+BDvUrxzyNM7ezRJUHo327rg4CZ0bVsUjP67Tdbuj+jT2mT3uj1bnDGaXG+Tv3bK2OYv7r3/pEtt3RyQKVXjmSZJtaV1wWc9DSf+WNT0+/3+DLrRD1+LgFo53xm7u1gA3KjhR9CYyQmDiTZ0RG0LL3ha14zC0bR3c2iOp+DnpTCW6s2cSljwzADUqlc3aMfqa3YiPT3mNWyL70iShIp64pLlh2zeSGaY2qkXp72KlIuauDNdWdQK/cPvgxk4enx/YyrgmC3amJCn68QD2R1Lj+o3BalUnDv1a6B/cGtWnccjdLgHgRJhmYwV7Q7ZNXXMGiapUKIfKFVgricgTBonIVjo1qOr1ZDZQZgmSlK459M51HQAA3RpVL35Oi6Ga5ffX08VNauDJIS1wd69Gqq53SJtaGN6+jmrrc2XptPJxV66XwXeRezbVv0ZN6yBPQNXsADf3iX54eGAz/wuqwGytqx/o38ToIahG6Sci9Y1LVWvL3a5eZf8LKXBRUjWsen4gZjyqflc2rdW1QZH0QITahOOVEW3QVuPPjxYW7MjwOJ1aC3f2TCr+2UrBXTOJCrLjXkyY1m4isjJ+a8l2vKXFB8rXoa9qRf2K0nZpWBVvXduh+PFVnRORNn54ibndWpzeuBdi7NG4uo8l7SUuNhovhFgDwpvy0erO6O3fsiamP9Ib1yaXLXbu0j7RmAuEj2/ujOXPDsD9ffUPHLw6sk3Ay95xcRLu6q1uMFAP857oi2/v7Gr0MIr983AvQ/6tS+ug8PPuiheaKTYeF6t9JYCacYEHWzo1qKLdQIK07NmBZZ6z03SRj25y3OTq1qhawO+5rUfD4p9vvzhJ7SHpYu/xLN229eywVmhZ29FcITqSl0GhCPZmop2yTonCBfeORKX4OpZ9dksXvHZF2zLPL392gKpjkNJxUL3GQ+czd2ofd6/sVLLGxtgry/6uFDgtUvpb1433ecKl5COhpHV9hBCoU7l8mS5RVXRI5W4QRA2gMSPaoEI565Xja5xQCRERIuRi+O6eGtICP4/qrmgdbetVNsWJf0IQwY7S3C/EzfC7uLwwXN1gtRItasXhf3d1M3oYPpnon06RmKgIXNa+Lra+OgTJSYEHiS5p7ZjyF0wB5gSTNRgINXMKAMZd1S6o5aMiBL77T1d8dFMnVIyx3rGA1NG9ceDfMaJwxCAR2ZKSk0ZfdyVrxsfi1u4NyzxfzqC7UWpe2JSPjsS713cs8Vy4FiFWi5IT31AZdcFUzUuW3R8PlC2urbaKFgz6hKpyeeW/64P9m6JbAFmCrimuZnaPgqywmOjI4r29meIMegRWXUZ29B10rF+tvOkvpE1WXidkrl8j1CB2MNMUv/tPt6CC61pT8m94Ved6frOef7znQlA8IkKgZnwsLmuvPOBuBVrMqBMAquuYWQ+o21Rl8ytD8N1/zB38JjIag0RkS3qf8MeoXDhX74MvAEjY5EzbRIz5i4b+6b+yk+/MNV+6epke0ahGRQzSuLitXTIJAqHn1BpPUzGmPtQTsx7ro9sY/KlSIfR9ZZ342OJAezh9hty9fW0HPNDP+7TBQC7eVz1fdgoYBS+xann/C6mkduVYXOdj2rLelN5Q+frOi3xmvPVoUh1rXhjksSOoEkprYOoh5YVLNFmv3jfB1NxFV4qJKlFagYjK4jeEbElJhk10kAX5AMcBR03XJgfWaStcL2zUpOXd1CAbgKhCyWfi6SEt1BuIxlwFR6MjhammCvmy7sVLvGZcBWqEn8wPNTWtWTKTcN4TfdE+sQqa14rTbQy+fH3HRWhRO/SxtKoTV3zhEcz1zme3dsHku8xTH0qJqMgIXFFqmrFLncqxAdVpC6a+kRKPDGjq8XmLfP19GtiyJn66R9kU0GCZab8pJbzeVXnjynb49JbOXt8rIBAbHYnalX1PoateKQYd61cJfZAejOhQF2tf1CYIoxatanPrfXoz5YGLFWWOElFwFAWJhBDVhBCzhRC7nP+v6mW5f4UQp4UQ/yjZHlGglBwUg+3a4I2S8y/3tNrEquURr0MhU38XSa/btD7Roqf7a7ZuQ6abKXhv6XpCatHqWmTrq0Ow8eUhxY+v6uz5YtcsqlYshy9vT8ZlCjreXZRUTbUuWv6UbpGupFW0Fvq3rGnIdhtUq4DeGnYR1Huv0bxWnMcaVb/c2wONalTUeTRljexYF9teHYrHB3sOYpsn1BG6ER3romZ8aMG27o2r45ouiUHX5jFTJ1Nfx8qbujXA0LZl95mli84bNe2wQjl1M8nV1K9FgmbZp7d0K1t6QUvtE6vgeRPVayOyO6WZRKMBzJVSNgMw1/nYkwkAblW4LaKAXa5orrnyA+o1XRIx9cFeitcDAIue6o/1Lw32+JoeJ3k3dnVkNVm9g0woGWJKaVG42h8z3R120WpEFcpFobzzBH3zK0Mw4ZqSNXQWPaVdANCfe/s0Lv65ea1KmPO4Y4pWpwZV8dFNnTHn8b6oV0W/6SVUVqOEShcuMIN4X6ERKYIac/+NFj/dH6+MaIP6JqlZc02XxOLvuSd1bPA9UjJtMjoyAm9d2yHofy8zHSpC+Uo1dgYwi7MBPSxTKz4GUx64OORxBcJMwTZ3Ux64GN/c2RVCgzkjQgBPDG6u/oqJyDSU7jpGAvjW+fO3AK7wtJCUci6ATIXbIgrYf69pj0vb1Q7pva1L3T33x1OR0aeGtEA7lVqRR0QIrxkeal6s2O+yp6SXLg+8Tbpaiop036TFQ3mBK/15rRQTVSIDb1CrWmhQ3biL3NHDWuKbOy8CANSKj0XTmiWnRTWtWcnUd6CDVVPnbklqZFP1bX7hLrsrntu7WQ2/74uxYS0L94Bl/WoVgm6lbmQR5CpBdPUyq3pV9Jmy585Mxwr3TKJAM6d/GtUDX9yWjChn7TRPtRyHta2Dzg08TnJQjVlr27j+pFoEsYQI/IbU3w+pc8OUiPSldM9WS0p52PnzEQCKqpMKIUYJIVKEECkZGRkKh0bhLDoyAjUqhXbR4uuOpSdJ1cum42fmFIS07WDlFqgYhfASJbJD55i08cPRr3nZ6SHNamo7fSacupv5YsSYjG5vK4Qo3ge19xIwfm54K9SKN1cr6lCZ9W66X85ht6nruDnw7vUdfQag3r+hI5qZpCaTmpRmDc15vK9KIynLDscgX/56sGeZILIezPSVDWX/kRAXg0GtL1x2VK8Ug/UvXYIRHRyZ5L/d1wPPD2+l2hitx/HF0eKfuWP9wAJv/VskqHbDVC16lG8gsgO/3xQhxBwAnlIynnd/IKWUQghFh3Ip5SQAkwAgOTnZ5qcFpDUjz38KdEohqaziHVR/3c3MdEKpltkeLmxqxsXgWGauKuu30qyUGY/21mzdWkxV9DeV765exhe4bFuvMv58sKfX1tT9W9TEyucGIWn0NJ1Hpj499w9q1mRyDfud6zpg7/Gs4sDexjGDESEE2r48s8TyIztqX/fKiGmqSmmZTeHvr2H1Y1MHlYspB6q8yl1ZlahQLhIx0Y7P0OA2oWWBA45pex/c2MkSXce0VqRRJpFeNfG0Em+DzEMiPfgNEkkpB3l7TQhxVAhRR0p5WAhRB8AxVUdHpICWtVlu6d4A/1uxH4DnqQf5Bfqc5KtZZ9iC1yWaWPW8ehfthtQkCjEgU7pIsZr0voiLiYowTW0mtbvp6K1y+WicOZ/vdzmrZhK5hl2+XCSSky5kn8XH8kKC7O2Grg1wMisf787ZafRQ0LVRNcRGR2LV8wNRVUF9JirLortmIjKY0ls/UwHc7vz5dgB/KVwfkWq0vGh5dcSFTl99PExjyiss1Gzb7njsN7dCTjfTjLfpMSufG4hVz3m9t0FBcn2eKsXYM0V/YCvHdJXIACLunurPlfbtf7oqHhOVFCa7NN1FR0bg0UHNdN3ms8NaenzedaisGReL6Ehz1vixGi1rEgXqxq4NDNs2ESmjdE88HsAlQohdAAY5H0MIkSyE+MK1kBBiMYBfAQwUQqQLIYZ4XBuRijTq5u1Yd4TAKLfuRaVVKKfPBZWaLcu9hTOYYRQ6ZiM4qH2O+tmtXfDLvT08vlYrPhaV3S7mlbSbJxRfsP3koUW6O6sGJ9+5rgOWjh6AmCjPU28+u7UL/n6oFyIjBN69vqPf9fX1cNOAlLHqZ4vKurdvE6OHoInYaPMFtlw1EY38/iiZOqiF4e3r4OObOxs9DCJLULRXk1KekFIOlFI2k1IOklKedD6fIqW822253lLKBClleSllopRypve1EqlD6wPjsLaOg5+ni4JqHrpsaEHPY79Vz9M3jRlsyHZfGN4Kr13R1v+CJtM4oWwhdqXUrkk0pE1t1IoPrBvQRzd1tnwNBU++uC1Z1+35615m1elmMVGRJTp7lTakTW20S6yM3W9civ4tauoyJgbmS9KiphmZi7+aiGa3/bVhfpfp0zwBQ9vUxv399AmUmSGTyGwm3tQZ7ROrGD0MIkswX+ibSCVaF2Xs1KAq0sYPR1sPRWnzC3Xqfa7iwd9f/RyrnsLFObN56lYpj+E6ZpXc3buxqoXF9VK3svcL5lDFmqRAqpFtutXm3tVHS65MrIp+ppvxOoS04u+zZcWP3q3dGxo9hGK737jU6CGEhe/+0xWf3toFzwz1POVOba7gt5ZZ9URkX/YsMkAE4P5+TXEyO6+4wHQgoiOVH03v79fE551pNalauFq9VZlSZITAxJs6o0uDvXj1n61GD8e0tLjYf+my1qhTORYfzU9Vf+UBmvdEX1SvaI9286FqUzceY0a0Ceo9Lwxvjf8b2NxvkIh3q63vqs71cLmzfXgork+uj59TDqg4osBY8dh1Ved6eGZYS1XOOZQKpB6XmupUjsXhMzklnmP2nLpWPjewONtWrSYOX92RjAbVAs80fnpoC1W2S0TGYCYR2Vb5cpF4akhwd2zUyD56ZmhL3TorqZmG7+8kzfhTWXXc2TMJC5/qh38e7mX0UMJG5QrReHKIsSeMjRMqlahVFI7qVI7FRW4dvAIRGSEC+rsZuX/4+s6LTJWZYVXvXNdR0ZS6/17TXsXRXBDoZ2tEh7r45ObOGNRKnyw7JYQQqBQT5bUWlp29dW2HMs8xRqQuLUoeDGhZC01rVlJ9vURkTgwSka3Z/eY204iDJ4RAw+oVPU4TtAM7fOa9FaUmzz69JbBCnJrerTfwc9e/RU2v9b/qV9Mnq5M0FOB0s6oVojGsXR18cbu+9bpCYYPddMh6Nq1Rpk4cM4k869SgSlDLR+l8Uqh3FhoR6YdBIrK1M9n5AS234SVjihsrZYeAAJG7CAF0bRRctku469XM+I5aZp1u9vdD1soYvK9vEyRWZWDLnR0LV/PiuiR2vfesisnrGi58qp/X125hdieRpXG3TLZWvVJgKbdqdNb49JbO+PEe322i1abHybPVu46Qf4ue6m/o9l+8rDVSX/ffHcau5j3RF/1bBB/oWf38IHx6S2dU8lMvyMWmiUQ+VamgT6dJNVzbJRGjh+k3Xdkq/MVT2iU6skK7Na4e0PrevLq94UXs29SNN3T7pU1/pDd6BPj3U9sdFyfhqcH6FHM2mxoBnqOaVWJVz9+jfi0SEB9rngDXJzd3xp8P9jR6GESWwiAR2VqwQRQlJ+dD29ZBjyY6n2TpeC3B6xZrcH3mm9cKvHZAg+rGXjAJXMhEaZLgGPc9vRuhY/0qxg1KR40TKqF5rbig35cQF4OhbR3dx5aNHoDbehh359YM+4cBLfVpUa+Vaha/YNTC5R3q+q2j1aVhNax78RJc2i6w7pUx0RGIMrhgtNkCga3rxvssWj6sbe2g1znrsT7FNWya1qyEFl72cWNGtAm7enGu5ibDA/zMWo0ZMkuHtnF8ZmOjIzCsXZ2wOZ8gUguDRGRrJjhOacoMB2IyJ60+G1pNzYyIEPj2P13x4yhHNt7zw1vjuUtbabItO6pbpXxxgM0bqWHhD732RYuf9p71Vrqbjq/OUSueHajamEoLNVh1UUPrT7Nc/uwAVdc3elhLRAQwNauqBoV6w03vZjU8Pt+8ViV8ckuXoNdXodyFotwf39wZMx/rE/LYrMBbdtjv9/fA5leGlHiucYKjS9hAlYusf357Mvo0T/BamygcarQ1ruH428bFOjJsx1weXEdPInJgkIhsze7FEFnWgEpzv1a/s2eS6utX447vtEcu1Im5Prk+buzaAADQt3kCalS60Ka+VrzjZ72LcVpVfHnf087ssDus72OaUMvaFy7SXr68NXa9fmmJ1/944OLin2tXjlV/cE6hBuMGtTZ/Vy5/6lQ2/0Wo3ucF7epVRh0NP29qqV+tQomC0h/e2AkbxwzGVGddr9LFpv0JdBqsXUx54GLMfqwPHurftPi5tPHD0aVhNd3+Fv1b1MR3/+nqMVPt5m4NMOV++0+5enxwc6SNH158LsR7qUShCa89OIWdogDOBr+4LRnlnXe8bjdouka5yAjkFRYF/T49Dn52D7TZ2cuXt8HXS9OMHkaxV0e2QfNacWhT90JnOV9tsxtWr4gFT/ZD/WoVEBkhsDH9NCqbvJBnqNT4mo3sUA9ZuYV44c/NKqwtOHpkEnnLdPDEfb/14z3dUb1SuZCm9JGx1Mp+u61HQ7SrVxlP/bZR98/BqD6Nsf3IWUycv1vX7Srla/rZY4OaI7+wCB/NT/W6TJUK5Uxbq0wLMVGRaFYrDk8OaeHz7wIAg1vXwuJdx5FUvaIuY3MF+DIyc1Vf92e3dsG9k9eUeM5bt0kisg5mEpGtVfRz9yZt/HAMal0LMVGRSBs/HI8PbuFzea28d0PHkN6nd9eXYC7SyFiBXluVnr7Tuo52BVVv65GE7kEWR02qUbG4E1D7xCpoqNNJtRm8MDy46XYREcJnRxktA76+LijVMvmubgEv6z7VpUeT6sWBgfeu74jXRho3/cCuNUjcuWdsGaV01osAcG1yfWx4aTBam6xotBk19FKnzrUvblM3Hq0UHit+u68Hfruvh6J1WNUt3Rti8ytDDK8HqIYhbcrWq3LVXNJTB2cBe9d5cbkoxyVuZAQvdYlCwW8OkQmEUhQS0CeTyH0b4dK218ot2GvGOaZoDQ3wM1UzPqbE4yeHBB8onfFo76Dfc2PX+hjLu43FPHVbUrtexV29Gqm6Pnf39W1sqn9Pb/vGKzrVw609knQdi7uJN3c2bNt66dSgakDLPTqwmd/gohqBzcs71MUjA5sBUGe6bCj0vqGjxM6xwzDn8b4eX+vb/EIXxkDOP96/oROGt69TXCfGXXJSNST7KUpuVT/c3Q0vX97a6+tCiLCbjqeWal7qj7kK3LsCnE8PbYl7+zbGyI7a38AgsiPuoYhMINROJ3p0SAnH6Wbf390Na/adwg2TVhg9lKBVrxSDDS8PRlyIJ6DRkcHdOygXFRHSHeVxV3mfZhaObu7WAI1qVMTNX6ws8fwt3RugsEj5lzDYeiLBEkIUFwol8qVDYmU8M7QlLm5aA7+tScffGw5pur0Pb+xU5rm3r+2At2ftxJLU45puG3BctO44kqn5dtTiysDwJNgzjtZ14zHxJvsHRku7uGkNXNw0uMzr2vGxOHI2p8RzwR6P/bFDfZ5/H+2NA6eycfUnywEAdSrH4vCZHNzRMwm39Ugqzs6Kj43Gs8PY/IIoVMwkIrIwtRJ7ykVF4AMPJ9LuRAj3Qq/unFji8eS7uga5BmNER0aUmK5iNZXLRwfUEYjMQwiBnqUuKqSUGHtFO8sE1MzW1tvsfF2M29VXdyRj8t3dii+gz+cX+lxeyUfqwxs74frk+h5f69SgKv53dzdsGqNNt0aXBU/2Q/vEKppuQ0+uLNvEauXZOENljTxkW71xVTsDRmJuNeNj0cVDJ0ghhC2m7xGZRfidoVDY+b9BzYwegmbUSmGfcv/FGKFBTZG3r+uAa7tcCBRVjInCqwbWA9HLE5c0N3oIxfxN51D6GfLXdp3CB68Zg7NpzGBT7Sv0MKBlLcTHXpjy5aoj4m3qjZJM1ss71PVZGB8A4mK1nX6W5Lzwt0v8dFSfxlj8dH+0rB2PAS1r4eZuDVDRwjdUzKCFl0LqaeOHl+j2SUSkJwaJyPb+b1BztKt3oZuS2bsjVQmiZoIVTjzHXdWuxB2yGy5qgPrVzN8mWUnw5OGB5glMeppqoSYrZ1yZndVmepphf3RdcqL/hTT2/PBWPuuaPTusJVrUikNMVKQp/mZGap9YBbteH4YxI+x988Au/8xCCNR31k8rFxWB169sh9mP98U713UweGTWNe2RXtg5dhik5fb4FzzYv4nRQ7DNd4zILBgkorDwy709MKpPYwDaFm9VQ0MPBWy90eOg6H7aEsp0kqjIiOLAnJSOE8snLlG/i5zawYpQL95u6tZA1XGoIdiudJxGYLxWdeKRWNX8wVR3VirOq6WmNePwy73euzbd27cJZj7WBwCgQrkpy4uOjMA1XRLROCF8OhfaSd0q5XFVZ+ODs1YVFRmh29RTrfbQl7QOrfmKEtMe6YXpj/RGrfhYAEAUT1yIVMUgEYWF8uUi8cTg5nhkQNPiYJEd6FoDJMhN3dP7QjBuwjXtMaxt7RIZXWp6YXirkDpsaSHGhHVGgp1KuPK5Qfj6jos0Gg0FYsajvRETFVrg8++HeuGqzvVUHpF/4Z4V4010pOMP46mDnV0bA3jqjrXhZd/1fyqWs3Hhc345yI/+LWoaPYSQdaxfRfPmCKW1qVsZrevG4/PbkvHu9R1Q0xksIiJ1KLqaEUJUE0LMFkLscv6/TN9TIURHIcRyIcQWIcRGIcT1SrZJFKqYqEg8PrgFYqPNOT3GNT0hJojxqXXeqcWFyvPDL7R/bVYrDp/c0qX4bpnaadWXd6iLhtX1vQttpXP+a70Ub/UmIS4G/Vta94Q13LVLrIxkD4U9yVhdGpZtDX9x0+oGjER7DT0UkPUXQLfydBsipex0A1NPCXExuLITM9mI1Kb0lvdoAHOllM0AzHU+Li0bwG1SyjYAhgJ4TwhRReF2iRQZ2bEuypssWPTwgKYAgHJBtDzVO05hobiI5h4b1Bz9WiSUed5qmQFWCnaFgyXP9MeaFwYZPYyQKPko/XB3N9XGYTa1K3u/w92spqPwe3ysvbJoPH0W/AaJnPvO3+/vgTevbo+O9av4/NuROQ1tUxuf35Zs9DAsR4/M8FC20bJ2HF6+vLX/BYnIVpQGiUYC+Nb587cArii9gJRyp5Ryl/PnQwCOASh7ZUWko/dv6IRtrw01ehgl1HamynZuUCXg90SodFLh6w7uIwOaoXODKhjSpjaSk9TJToiMUHdKlrfAjGuahxYEYLpAY6AiFc7d/3lU9+Kf29aNVzoccpNYtQKqW7SjTTi2dA/EwwMcheyl1SLICpS+GB13VbuAL1BjoiJx3UX18eeDPREdxE0TMwunWPynt3bBJa1rGT0MS2qfqM2UfCUGtqqJO3uau5YnEalP6dG3lpTysPPnIwB8HhWEEF0BlAOw28vro4QQKUKIlIyMDIVDI7KWZrXiMOfxvnh0UOAtkfXIAmlQvQKmPNATlctH494+jfGaCi3sh7WtXVxMWcsWr/88HHqdIn9/WyHUC9Lpzf1iNZTr1jZutaXcpxWSebgKuV/arjZm/l8fXbbZr0VNPBpqZz9rfpUC4itYbddi36HEoa0eQ9O7JgvZzyPOgPJAk0z3vrRdbTw6MPBzUiKyD79BIiHEHCHEZg//jXRfTjquOrwe4oUQdQBMBnCnlLLI0zJSyklSymQpZXJCApONKPw0rVkpqCwPvWMUERECSTWU1/6JjozA5Lu6YfojvTH90V6K1+ctE6pF7biQ1+nv4k0I4fHC1mqBo6IQrszcg0zMHjGnyzvUxXOXtsTb13ZU9D0IRmSEwGOXhHhB4edj+OywlqGtlwwhhMDip/sXP65aIdrve1wfAb13oT11qAtlscMCEQDgqk6JPMYThSm/k+CllF6LIwghjgoh6kgpDzuDQMe8LBcPYBqA56WUK0IeLRGVoNZd6GDiBGre+W5dNx7Hz+Wqtj41BXJSXzogdEv3Bnh0UIiZFDqKjoxAboHHWD3ZRGSEwKg+TYwehl9VK0Tjqzsuwvm8Qq/LdGpQBff2Nf/vUtqfD/bE4dPnkVPg/Xezs/rVKmDX68MwY/MRDGnjv0W2K+NK7+yqL2+/CEfO5KDfWwtUW+frV7ZF27oXMi5dv9Ol7WrjgX5NVdsOkZYsntxHRAooDQ9PBXC78+fbAfxVegEhRDkAfwD4Tkr5m8LtEZE73p00TO34WLSrV7Iez9gr2qFyef93zI20bPSA4gKySdUrBFUonUhtPZpUR6cGVW25L+tYvwqGtatT/DgcL7iiIyMwokPdgOoRTbypM+7t2xit6uiT+eYSGx0ZUIHsn9xqsflzc7eG6FC/SpnnmyRUQtt65qs7Q+Hp2i7sCkZEnim9OhgP4BIhxC4Ag5yPIYRIFkJ84VzmOgB9ANwhhFjv/K+jwu0SEdS7rgrm4qVijLrFmq1ahyIuNgp392qM6Y+EXvdIT3f2TAIA1K1SvviC7c8HeyJCYRFrIvLNrnWH1Fa/WgU8O6yVLl2eQtG9cejT0kz6K1GYKf0xnHBtB1Qsp9453VWd66m2LiIylqIgkZTyhJRyoJSymZRykJTypPP5FCnl3c6f/yeljJZSdnT7b70KYycKe0acTHdqUBXv39BRtfXFqdD62RVo+kLFtrs14/wX1I6IEGhdNx7PDG2J165oq9q2tfDy5W3KFFYNNUDHGgWkNgZSyM5u6tYAFyVVxa09Gho9FApj5T0EhHydRwa7V3772g7YO+7SIN9FRGbEM30iC1MtkyjIaMHIjurdLYqNjlTcFcbVJnlQ61poo1JL9uqVYrDh5cEBLXt/vya4tbt1Tv6VxhZjotTNJqPwFciuZ3Br//VsrKpSbBTqVSmPN65qZ/RQSEM1KsXg1/suRs04/9PaiLQSGx2J9S9dUuK5YM//fBFCmDYTkIiCo/wWPhEZRo1jcYfEymhVR53Aip6GtKmFRwY2w8FT55EQQNZPKMxeX0gpi870ozDy5ODmuK9vY6OHoQpP12KREQJLRw/QfzBUglWnPZvJimcHGj0ECkCVCuWMHgIRWQAziYgsTI0pGn891Aux0dbJDHlkgKMzTKs68WhTtzIGl+qaw5N9/wL91KSNH44Pbuyk6ViIfImLjQ7qzvTw9nUBAF0aVtVqSEHjjfXw8d71HdE+MTwLU9euHBtQAXDyzojTF2b+EJEnDBIRWVg4HNt/va9HiceuExoGg5QLNs28W6NqGo2E7Grbq0N9vu76CKq1L+vbPAFp44ejaU19O2SRtUmVLs+v6FQPUx/qpcq6KHxpfW738c2d0atpDb/LtajN/ShRuGKQiMjC7BQjmvN4n4CWc508GR0jqlO5vMEjCF1xoC2AZd0DSa7aT0SB8nbx/cM93QA4uu35Eg6BcCIiPV3arg7+d7djH+xrF1u/WgV9BkREpsMzfiIrs9EFlKc7/3Of6Ov9VzQwlWjaI73QzsJTClx/U2ZjkdYiIzx/gy9uUgMf39wZzwxrAcD7Z9EOn1HXdF41OjmSNuzwOSNSw7wn+ho9BCIyAZ6xEFmYkW2jRw9riZa149C4RiX8vfEQasbF4KnfNgIAFjzZL6R17n7jUjR5bnrx4yYJlZCSdbLEMnGxjmLSFWKM2321qWvdABEQenYGszooELteH4bz+YU4eOo8YqIiMefxvhj1XQr2HM8qsdyl7eoYNEJ9XdKqFl4Y3go3dm1g9FCIiEro3bwGpm86Uvy4cUIlA0dDRGbBTCIiCzPyov2+vk3Qr0VNNKheAQ/2b4pmtRyZQO0TKyOpRsWQ1ukt68DdbT0a4vlLW+E/PRt5fP1hZ2FrtVzcpLqq6zODFy9rjbjYKFSpYO/ubWSM6MgIxMdGF3dNbFqzEprW9H3hYecAZESEwN29G6OigYFtIiJP3rmuIxY+1c/oYRCRyTBIRGRhZrquinIGeJR2Svvk5s4lHpe+eIyOjMA9fRqjXJTn3Vef5gmKtl/aD/d0xw0X1Vd1nUYb2bEeNo0ZwhpDREREYSw2OhINq4d2Y4+I7Iu3tYgsrGODKqgdH4sjZ3OMHgra1I3H45c0x/UKAyrD2tXBnjcuLS53G2wgo0I5ZUEqKqlnAB1QiNTStVE1rNp7YYppsB34iLQ05/E+2HciG3d9m2L0UIhUNbh1LQxvHx5TgInIP95GJrKwmKhIfH5bctDv+97Z1UJNQgg8MrAZasXHKl5XRIQonnrWrl5ljB7WMqhxqM3OU2H8qVEpBnOdhSx72HDqHRFRhXKRGNy6lt/lmtaMw8BW/pcjCoWRQfFJtyVjZMd6hm2fiMyFQSKiMDP3ib6Wyg4RQuC+vk1QOz4WV3XiCYwRmiRUwtLRA3BfnyZGD4WISHVCCEwK4YYLkTaMvTNVKz4GXZOqGToGIjIWp5sRWZynLJeEuBhkZOZ6XL6JRTtXrHhuoNFDCGv1qpQ3eggUhjo1qGr0EIiIwsrK5wYZPQQiMhiDREQ2FMg9qLqVY3E8K0/zsRARhWLH2KGIiWKNMSIiIiI9MUhEZHGh1stZ/MwAFoUN0k3dGuCe3o2NHgaR5VyXXB+zth7F6GEtMahVzYDewwARmd1TQ1pgwswdRg+DiIhIVQwSEVmcCHHuuqMwdBhXZA5Bm7rxaFSDrWKJgjWodS2kjR9u9DCIVPVg/6YMEhERke2wcDWRzTStac2aQ0QUvjokVkHH+lXw0mWt8ejAZkYPh6iEdvUqGz0EIiIi3TCTiMhm/nm4F/pOmG/0MGwp1KwtOxrQsiYvnEg15ctF4s8HewIA2tarjMcuaW7wiIgcJt3aBYPb1DZ6GERERLpRlEkkhKgmhJgthNjl/H+ZNiRCiIZCiLVCiPVCiC1CiPuUbJOISnKvSRQZIRAbHYkejat7XHbhU/30GZRNSbCGk8tXd1zEC3kisj0RauE/oiC1dd54uS450eCREFG4U5pJNBrAXCnleCHEaOfjZ0otcxhADyllrhCiEoDNQoipUspDCrdNRPBcuPq/17QHAPy5vuTXrGF11tMJDS8SiIjsbkibWpi55WiJ5/w1eHj72g7OGn9EytStUp6124jIFJQGiUYC6Of8+VsAC1AqSCSldO+xHQPWQSJSlacpUDFRkWicwNpE6mEGERGR3X10U2dk5xaiw6uzAn7P1V2Y9UFERPaiNGBTS0p52PnzEQC1PC0khKgvhNgI4ACA/3rLIhJCjBJCpAghUjIyMhQOjYiIiIgoMNGREahcIdroYRARERnKbyaREGIOAE8V+553fyCllEIIj7fbpZQHALQXQtQF8KcQ4jcp5VEPy00CMAkAkpOTeeueKADu0838pcVTqDiVgIiIiIiI7M9vJpGUcpCUsq2H//4CcFQIUQcAnP8/5mddhwBsBtBbjcETkffwRel40fd3d9N8LHYVHen4K0eygCkRke1Ne6SX0UMgIiIyjNKaRFMB3A5gvPP/f5VeQAiRCOCElPK8s/tZLwDvKtwuETkFErcoHx2Jnk1raD8Yk3jtirbokKhee/YnBrdAVEQErurM2hNERHbXpu6F4we7mxERUbhRGiQaD+AXIcRdAPYBuA4AhBDJAO6TUt4NoBWAt51T0QSAt6SUmxRul4j8COd27bd2b6jq+iqXj8ZLl7dWdZ1ERGR+FWMijR4CERGRrhQFiaSUJwAM9PB8CoC7nT/PBtBeyXaIyBfPdzmv6ZKI75bvw8msPNSuHKvzmIiIiKyrSUJF7M7IQpXy5YweChERka6UZhIRkcHcM+EfHtCs+OfEqhWw9sVL8Nf6g+jWqLoBIyMiIrKm6EilDYCJiIisiUEiIotzxYiSqlfAY5c0L/P6yI719B0QERERERERWRJvkxBZXEy0o15CrXhOKSMiIiIiIqLQMZOIyOLqVSmP92/oiN7NEoweChERUVgY2bGu0UMgIiLSBINERDbAKWVERETqiXVm6UZ4yLnfNGYwykez6xkREdkTg0RERERERG4+vrkzfl59AC1qxZV5LS422oARERER6YNBIiIiIiIiN3WrlPfYDIKIiMjuWLiaiIiIiIiIiIgYJCIiIiIiIiIiIgaJiIiIiIiIiIgIDBIREREREREREREYJCIiIiIiIiIiIjBIREREREREREREYJCIiIiIiIiIiIjAIBEREREREREREQEQUkqjx+CRECIDwD6jx6GSGgCOGz0IIgvgd4UoMPyuEAWG3xWiwPC7QhQYu3xXGkopEzy9YNogkZ0IIVKklMlGj4PI7PhdIQoMvytEgeF3hSgw/K4QBSYcviucbkZERERERERERAwSERERERERERERg0R6mWT0AIgsgt8VosDwu0IUGH5XiALD7wpRYGz/XWFNIiIiIiIiIiIiYiYRERERERERERExSERERERERERERGCQSHNCiKFCiB1CiFQhxGijx0OkNSFEfSHEfCHEViHEFiHEo87nqwkhZgshdjn/X9X5vBBCfOD8jmwUQnR2W9ftzuV3CSFud3u+ixBik/M9HwghhP6/KZE6hBCRQoh1Qoh/nI8bCSFWOj/fPwshyjmfj3E+TnW+nuS2jmedz+8QQgxxe57HILIFIUQVIcRvQojtQohtQogePK4QlSWEeMx5/rVZCPGjECKWxxUiQAjxlRDimBBis9tzmh9HvG3DzBgk0pAQIhLARADDALQGcKMQorWxoyLSXAGAJ6SUrQF0B/Cg83M/GsBcKWUzAHOdjwHH96OZ879RAD4BHDtUAC8D6AagK4CX3XaqnwC4x+19Q3X4vYi08iiAbW6P/wvgXSllUwCnANzlfP4uAKecz7/rXA7O79cNANrA8V342Bl44jGI7OR9AP9KKVsC6ADHd4bHFSI3Qoh6AB4BkCylbAsgEo7jA48rRMA3KLtv1+M44m0bpsUgkba6AkiVUu6RUuYB+AnASIPHRKQpKeVhKeVa58+ZcJzI14Pjs/+tc7FvAVzh/HkkgO+kwwoAVYQQdQAMATBbSnlSSnkKwGwAQ52vxUspV0hH5f3v3NZFZClCiEQAwwF84XwsAAwA8JtzkdLfFdd36DcAA53LjwTwk5QyV0q5F0AqHMcfHoPIFoQQlQH0AfAlAEgp86SUp8HjCpEnUQDKCyGiAFQAcBg8rhBBSrkIwMlST+txHPG2DdNikEhb9QAccHuc7nyOKCw405Y7AVgJoJaU8rDzpSMAajl/9vY98fV8uofniazoPQBPAyhyPq4O4LSUssD52P3zXfydcL5+xrl8sN8hIqtpBCADwNfCMTXzCyFERfC4QlSClPIggLcA7IcjOHQGwBrwuELkjR7HEW/bMC0GiYhIE0KISgB+B/B/Usqz7q85I+zSkIERmYQQ4jIAx6SUa4weC5HJRQHoDOATKWUnAFkola7P4woR4Jz2MhKOwGpdABXBqZNEAdHjOGKVYxWDRNo6CKC+2+NE53NEtiaEiIYjQPS9lHKK8+mjzlRMOP9/zPm8t++Jr+cTPTxPZDU9AYwQQqTBkbI/AI66K1Wc0wSAkp/v4u+E8/XKAE4g+O8QkdWkA0iXUq50Pv4NjqARjytEJQ0CsFdKmSGlzAcwBY5jDY8rRJ7pcRzxtg3TYpBIW6sBNHN2FCgHRwG4qQaPiUhTzrnsXwLYJqV8x+2lqQBcHQBuB/CX2/O3ObsIdAdwxpmSORPAYCFEVeedscEAZjpfOyuE6O7c1m1u6yKyDCnls1LKRCllEhzHh3lSypsBzAdwjXOx0t8V13foGufy0vn8Dc4uNY3gKJa4CjwGkU1IKY8AOCCEaOF8aiCAreBxhai0/QC6CyEqOD/Lru8KjytEnulxHPG2DdOK8r8IhUpKWSCEeAiOD1MkgK+klFsMHhaR1noCuBXAJiHEeudzzwEYD+AXIcRdAPYBuM752nQAl8JRFDEbwJ0AIKU8KYR4DY4TEgB4VUrpKjb3ABwdCsoDmOH8j8gungHwkxBiLIB1cBbrdf5/shAiFY7CizcAgJRyixDiFzguBAoAPCilLAQAHoPIRh4G8L3zwnQPHMeKCPC4QlRMSrlSCPEbgLVwHA/WAZgEYBp4XKEwJ4T4EUA/ADWEEOlwdCnT4/rE2zZMSziCxUREREREREREFM443YyIiIiIiIiIiBgkIiIiIiIiIiIiBomIiIiIiIiIiAgMEhERERERERERERgkIiIiIiIiIiIiMEhERERERERERERgkIiIiIiIiIiIiAD8P+ZG4nB3f4xVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix input for all tests using sample librispeech data\n",
    "speech_input = np.expand_dims(np.pad(dataset['validation'][0][\"audio\"][\"array\"][:AUDIO_MAXLEN], (0, AUDIO_MAXLEN-len(dataset['validation'][0][\"audio\"][\"array\"][:AUDIO_MAXLEN]))), 0)\n",
    "print(speech_input.shape)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,4)\n",
    "sns.lineplot(data=speech_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a2f5cd-3df2-46f9-bb34-54337c38eaf6",
   "metadata": {},
   "source": [
    "### compare model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ecbcb1-2539-49dc-a674-cf194a8e2b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 312, 32)\n"
     ]
    }
   ],
   "source": [
    "hugging_model.to(\"cuda\")\n",
    "r = hugging_model(torch.from_numpy(speech_input).to(\"cuda\"))\n",
    "hugging_prediction = r.logits.detach().cpu().numpy()\n",
    "print(hugging_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48a4d8c7-ef1e-4d9c-be00-7270a7ea1330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "gpu_model.to(\"cuda\")\n",
    "_ = gpu_model.eval()\n",
    "print(next(gpu_model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf0b9f4-17e0-429a-96fc-2aa578b71371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 312, 32)\n"
     ]
    }
   ],
   "source": [
    "torch_prediction = gpu_model(torch.from_numpy(speech_input).to(\"cuda\"))[0].detach().cpu().numpy()\n",
    "print(torch_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e50f76bc-bbc1-4f8b-803d-3119f8e59520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(hugging_prediction, torch_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a8631-06b9-49cf-8352-14cf8eec8e21",
   "metadata": {},
   "source": [
    "## export PyTorch to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59624955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2359: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/symbolic_helper.py:716: UserWarning: allowzero=0 by default. In order to honor zero value in shape use allowzero=1\n",
      "  warnings.warn(\"allowzero=0 by default. In order to honor zero value in shape use allowzero=1\")\n"
     ]
    }
   ],
   "source": [
    "# export with native torch onnx\n",
    "torch.onnx.export(imported_model,     # model being run \n",
    "     dummy_input,                     # model input (or a tuple for multiple inputs) \n",
    "     \"wav2vec2-ctc.onnx\",             # where to save the model  \n",
    "     export_params=True,              # store the trained parameter weights inside the model file \n",
    "     opset_version=14,                # the ONNX version to export the model to. max supported in this notebook setup is 14\n",
    "     do_constant_folding=True,        # whether to execute constant folding for optimization \n",
    "     input_names = ['modelInput'],    # the model's input names \n",
    "     output_names = ['modelOutput'],  # the model's output names \n",
    "     dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes \n",
    "                   'modelOutput' : {0 : 'batch_size'}}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c733167-d871-4a2a-bdf4-ccb66f224719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted model to fp16 in: 1.528 s\n"
     ]
    }
   ],
   "source": [
    "# convert to fp16\n",
    "s = time.perf_counter()\n",
    "onnx_model = onnxmltools.utils.load_model(\"wav2vec2-ctc.onnx\")\n",
    "onnx_model = onnxmltools.utils.float16_converter.convert_float_to_float16(onnx_model)\n",
    "onnxmltools.utils.save_model(onnx_model, \"wav2vec2-ctc.fp16.onnx\")\n",
    "e = time.perf_counter()\n",
    "time.sleep(0.5)\n",
    "print(f\"converted model to fp16 in: {(e-s):.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e76124-cc39-4e75-aae4-3f39cd3859f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (not working on wav2vec) export PyTorch to TRT with torch_tensorrt\n",
    "\n",
    "torch_tensorrt (TRTorch) uses TorchScript as an intermediate format, so test conversion with `torch.jit.script()` and `torch.jit.trace()`.\n",
    "\n",
    "then, demonstrate working conversion on a small test model.\n",
    "\n",
    "however, kernel dies (segfault) when converting actual model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2396e969-7e81-4a1c-aeac-d66921afe467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing weight_norm from ConvolutionalPositionalEmbedding\n"
     ]
    }
   ],
   "source": [
    "# scripting works\n",
    "scripted_model = torch.jit.script(imported_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "813b99cd-831f-46b4-9258-59f5bea9ebb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: RuntimeError: Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n"
     ]
    }
   ],
   "source": [
    "# tracing raises an error\n",
    "try:\n",
    "    traced_model = torch.jit.trace(imported_model, dummy_input, strict=False)\n",
    "except Exception as e:\n",
    "    print(f\"error: {type(e).__name__}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fddc670e-9394-4ef3-9486-1c3484b32f93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - Cannot infer input type from calcuations in graph for input input.1. Assuming it is Float32. If not, specify input type explicity\n"
     ]
    }
   ],
   "source": [
    "test_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(100, 100),\n",
    "    torch.nn.Linear(100, 100),\n",
    "    torch.nn.ReLU()\n",
    ")\n",
    "\n",
    "trt_test_model = torch_tensorrt.compile(test_model, \n",
    "    inputs= [torch_tensorrt.Input((1, 100))],\n",
    "    enabled_precisions= {torch_tensorrt.dtype.float, torch_tensorrt.dtype.half} # Run with FP16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a0de3fc-f788-4541-be79-ec1b54c5a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THIS WILL FAIL...\n",
    "# trt_model = torch_tensorrt.compile(imported_model, \n",
    "#     inputs= [torch_tensorrt.Input((1, AUDIO_MAXLEN))],\n",
    "#     enabled_precisions= {torch_tensorrt.dtype.float, torch_tensorrt.dtype.half} # Run with FP16\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ac54d-cf9b-433a-ae4a-4391c7ecb150",
   "metadata": {
    "tags": []
   },
   "source": [
    "### export ONNX to TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3811330a-869e-4bbe-8bf8-950b2327a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32885630-80c5-48aa-a36b-699845b28268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export helper functions for tensorRT\n",
    "# adapted for wav2vec from https://developer.nvidia.com/blog/speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt/\n",
    "\n",
    "def build_engine(onnx_path, shape):\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "        builder.create_network(1) as network, \\\n",
    "        builder.create_builder_config() as config, \\\n",
    "        trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        config.max_workspace_size = (256 << 20)\n",
    "        with open(onnx_path, 'rb') as model:\n",
    "            parser.parse(model.read())\n",
    "            network.get_input(0).shape = shape\n",
    "            engine = builder.build_engine(network, config)\n",
    "            return engine\n",
    "\n",
    "def save_engine(engine, file_name):\n",
    "    buf = engine.serialize()\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(buf)\n",
    "        \n",
    "def load_engine(trt_runtime, plan_path):\n",
    "    with open(plan_path, 'rb') as f:\n",
    "        engine_data = f.read()\n",
    "    engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b07c00f5-f870-47bd-8fe4-40054b9d4742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/15/2022-05:50:34] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:364: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1070/44071790.py:13: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for trt export: 29.813 s\n",
      "model exported as  : wav2vec2-ctc.trt\n"
     ]
    }
   ],
   "source": [
    "s = time.perf_counter()\n",
    "\n",
    "onnx_file_name = 'wav2vec2-ctc.onnx'\n",
    "tensorrt_file_name = 'wav2vec2-ctc.trt'\n",
    "input_shape = [1, AUDIO_MAXLEN]\n",
    "\n",
    "engine = build_engine(onnx_file_name, input_shape)\n",
    "save_engine(engine, tensorrt_file_name) \n",
    "\n",
    "e = time.perf_counter()\n",
    "time.sleep(0.5)\n",
    "print(f\"time for trt export: {e-s:.3f} s\")\n",
    "print(f\"model exported as  : {tensorrt_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "061f10e6-76ae-4f12-8cb3-dee0e5480217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1070/44071790.py:13: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for trt export: 26.269 s\n",
      "model exported as wav2vec2-ctc.fp16.trt\n"
     ]
    }
   ],
   "source": [
    "s = time.perf_counter()\n",
    "\n",
    "onnx_fp16_file_name = 'wav2vec2-ctc.fp16.onnx'\n",
    "tensorrt_fp16_file_name = 'wav2vec2-ctc.fp16.trt'\n",
    "input_shape = [1, AUDIO_MAXLEN]\n",
    "\n",
    "engine = build_engine(onnx_fp16_file_name, input_shape)\n",
    "save_engine(engine, tensorrt_fp16_file_name) \n",
    "\n",
    "e = time.perf_counter()\n",
    "time.sleep(0.5)\n",
    "print(f\"time for trt export: {e-s:.3f} s\")\n",
    "print(f\"model exported as {tensorrt_fp16_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d67724-7a0d-4b9a-bec4-aacec0a9ea12",
   "metadata": {},
   "source": [
    "# ======================== INFERENCE ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e15a548-c315-4a41-a535-8eb45ee2ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iters = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd0ac3-036a-44a0-b21e-8e9cfd8550ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## test PyTorch vs ONNX inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8de0230-a631-4530-9f5f-9da75e772166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 512/512 [00:06<00:00, 77.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for torch GPU inference: 12.977 ms per inference\n"
     ]
    }
   ],
   "source": [
    "s = time.perf_counter()\n",
    "with torch.no_grad():\n",
    "    for _ in tqdm.trange(test_iters):\n",
    "        prediction = gpu_model(torch.from_numpy(speech_input).to(\"cuda\"))\n",
    "e = time.perf_counter()\n",
    "time.sleep(0.5)\n",
    "torch_inference = e - s\n",
    "print(f\"time for torch GPU inference: {torch_inference*1000./test_iters:.3f} ms per inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30dc82ba-7c05-4dab-8e94-3522b9b345e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unallocate this vram (it won't be released though fyi)\n",
    "del gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7883517-9a60-4bc7-a763-6ad97e03fa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 stats:\n",
      "total    : 11534336.00 MB\n",
      "free     :  6459072.00 MB\n",
      "used     :  5075264.00 MB\n"
     ]
    }
   ],
   "source": [
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(\"GPU 0 stats:\")\n",
    "print(f'total    : {info.total/1024.:>11.2f} MB')\n",
    "print(f'free     : {info.free/1024.:>11.2f} MB')\n",
    "print(f'used     : {info.used/1024.:>11.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f13147-37b8-4eda-b1a1-e172e6a68314",
   "metadata": {},
   "source": [
    "### ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "852d68a1-3958-4e1a-9ba0-80b0898d4b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model 'wav2vec2-ctc.onnx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:350: UserWarning: Deprecation warning. This ORT build has ['CUDAExecutionProvider', 'CPUExecutionProvider'] enabled. The next release (ORT 1.10) will require explicitly setting the providers parameter (as opposed to the current behavior of providers getting set/registered by default based on the build flags) when instantiating InferenceSession.For example, onnxruntime.InferenceSession(..., providers=[\"CUDAExecutionProvider\"], ...)\n",
      "  warnings.warn(\"Deprecation warning. This ORT build has {} enabled. \".format(available_providers) +\n"
     ]
    }
   ],
   "source": [
    "print(f\"loading model '{onnx_file_name}'\")\n",
    "ort_model = onnxruntime.InferenceSession(onnx_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1e843ee-0d65-4de4-80c7-003bf10152c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 312, 32)\n"
     ]
    }
   ],
   "source": [
    "speech = np.copy(speech_input).astype(np.float32)\n",
    "ort_inputs = {\"modelInput\": speech}\n",
    "ort_outs = ort_model.run(None, ort_inputs)\n",
    "ort32_prediction = np.array(ort_outs)[0]\n",
    "print(ort32_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14383929-2b4f-47fc-82cb-d53930b571a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 512/512 [00:07<00:00, 66.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for onnx-runtime fp32 GPU inference: 15.090 ms per inference\n"
     ]
    }
   ],
   "source": [
    "s = time.perf_counter()\n",
    "for _ in tqdm.trange(test_iters):\n",
    "    ort_outs = ort_model.run(None, ort_inputs)\n",
    "e = time.perf_counter()\n",
    "time.sleep(0.5)\n",
    "ort32_inference = e - s\n",
    "print(f\"time for onnx-runtime fp32 GPU inference: {ort32_inference*1000./test_iters:.3f} ms per inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f805ca2-05e9-41a4-9560-518354e0ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ort_model\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb399b38-4dab-48e9-a67c-6b67718f0a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 stats:\n",
      "total    : 11534336.00 MB\n",
      "free     :  6405824.00 MB\n",
      "used     :  5128512.00 MB\n"
     ]
    }
   ],
   "source": [
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(\"GPU 0 stats:\")\n",
    "print(f'total    : {info.total/1024.:>11.2f} MB')\n",
    "print(f'free     : {info.free/1024.:>11.2f} MB')\n",
    "print(f'used     : {info.used/1024.:>11.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099b30e-6bea-4c12-b02d-5f04fde83fac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ONNX FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31cac2c7-a2a9-4375-9ef6-ef036b68476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model 'wav2vec2-ctc.fp16.onnx'\n"
     ]
    }
   ],
   "source": [
    "print(f\"loading model '{onnx_fp16_file_name}'\")\n",
    "ort16_model = onnxruntime.InferenceSession(onnx_fp16_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c71e5ea4-e8b2-4fb8-aeac-61550eb3a02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 312, 32)\n"
     ]
    }
   ],
   "source": [
    "speech16 = np.copy(speech_input).astype(np.float16)\n",
    "ort16_inputs = {\"modelInput\": speech16}\n",
    "ort16_outs = ort16_model.run(None, ort16_inputs)\n",
    "ort16_prediction = np.array(ort16_outs[0])\n",
    "print(ort16_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f41919e-9173-4006-b20b-85a7a40f2360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 512/512 [00:03<00:00, 129.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for onnx-runtime fp16 GPU inference: 7.707 ms per inference\n"
     ]
    }
   ],
   "source": [
    "ort16_inputs = {\"modelInput\": speech16}\n",
    "s = time.perf_counter()\n",
    "for _ in tqdm.trange(test_iters):\n",
    "    ort_outs = ort16_model.run(None, ort16_inputs)\n",
    "e = time.perf_counter()\n",
    "time.sleep(0.5)\n",
    "ort16_inference = e - s\n",
    "print(f\"time for onnx-runtime fp16 GPU inference: {ort16_inference*1000./test_iters:.3f} ms per inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cac3de6-61c7-4645-a424-8f97b575d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ort16_model\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56763e1b-9ae0-4a58-9911-3384134e0240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 stats:\n",
      "total    : 11534336.00 MB\n",
      "free     :  6405824.00 MB\n",
      "used     :  5128512.00 MB\n"
     ]
    }
   ],
   "source": [
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(\"GPU 0 stats:\")\n",
    "print(f'total    : {info.total/1024.:>11.2f} MB')\n",
    "print(f'free     : {info.free/1024.:>11.2f} MB')\n",
    "print(f'used     : {info.used/1024.:>11.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be5963-8d81-4d3c-8048-caa8c4c4d587",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d03475d6-504d-48a4-bf4c-595f854548ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stackoverflow coming through to fix nvidia's example\n",
    "# https://stackoverflow.com/questions/59280745/inference-with-tensorrt-engine-file-on-python\n",
    "\n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    \n",
    "class TRTModel:\n",
    "    \n",
    "    def __init__(self,engine_path, max_batch_size=1, dtype=np.float32):\n",
    "        \n",
    "        self.engine_path = engine_path\n",
    "        self.dtype = dtype\n",
    "        self.logger = trt.Logger(trt.Logger.WARNING)\n",
    "        self.runtime = trt.Runtime(self.logger)\n",
    "        self.engine = self.load_engine(self.runtime, self.engine_path)\n",
    "        self.max_batch_size = max_batch_size\n",
    "        self.inputs, self.outputs, self.bindings, self.stream = self.allocate_buffers()\n",
    "        self.context = self.engine.create_execution_context()\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_engine(trt_runtime, engine_path):\n",
    "        trt.init_libnvinfer_plugins(None, \"\")             \n",
    "        with open(engine_path, 'rb') as f:\n",
    "            engine_data = f.read()\n",
    "        engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "        return engine\n",
    "    \n",
    "    def allocate_buffers(self):\n",
    "        \n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        bindings = []\n",
    "        stream = cuda.Stream()\n",
    "        \n",
    "        for binding in self.engine:\n",
    "            size = trt.volume(self.engine.get_binding_shape(binding)) * self.max_batch_size\n",
    "            host_mem = cuda.pagelocked_empty(size, self.dtype)\n",
    "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            \n",
    "            bindings.append(int(device_mem))\n",
    "\n",
    "            if self.engine.binding_is_input(binding):\n",
    "                inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "            else:\n",
    "                outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "        \n",
    "        return inputs, outputs, bindings, stream\n",
    "       \n",
    "            \n",
    "    def __call__(self,x:np.ndarray, dim_1=312, dim_2=32):\n",
    "        x = x.astype(self.dtype)\n",
    "        np.copyto(self.inputs[0].host,x.ravel())\n",
    "        for inp in self.inputs:\n",
    "            cuda.memcpy_htod_async(inp.device, inp.host, self.stream)\n",
    "        self.context.execute_async(batch_size=self.max_batch_size, bindings=self.bindings, stream_handle=self.stream.handle)\n",
    "        for out in self.outputs:\n",
    "            cuda.memcpy_dtoh_async(out.host, out.device, self.stream) \n",
    "        self.stream.synchronize()\n",
    "        return [out.host.reshape(self.max_batch_size, dim_1, dim_2) for out in self.outputs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd181e1b-eb15-44e1-ab90-7f5cd54664c2",
   "metadata": {},
   "source": [
    "### FP32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90b42a86-78b9-4d24-afc5-7fd0f0f4fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model 'wav2vec2-ctc.trt'\n",
      "(1, 312, 32)\n"
     ]
    }
   ],
   "source": [
    "print(f\"loading model '{tensorrt_file_name}'\")\n",
    "speech = np.copy(speech_input).astype(np.float32)\n",
    "model = TRTModel(tensorrt_file_name)\n",
    "trt32_prediction = model(speech)[0]\n",
    "print(trt32_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbbd93b0-965d-4adf-9852-f4ae6956af82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 512/512 [00:05<00:00, 94.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for TensorRT fp32 GPU inference: 10.539 ms per inference\n"
     ]
    }
   ],
   "source": [
    "s = time.perf_counter()\n",
    "for _ in tqdm.trange(test_iters):\n",
    "    out = model(speech)\n",
    "e = time.perf_counter()\n",
    "time.sleep(0.5)\n",
    "trt32_inference = e - s\n",
    "print(f\"time for TensorRT fp32 GPU inference: {trt32_inference*1000./test_iters:.3f} ms per inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9780dba1-24fe-4215-a80b-fcb9efeffbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92cbe753-3f24-4405-8748-f19838a35487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 stats:\n",
      "total    : 11534336.00 MB\n",
      "free     :  6405824.00 MB\n",
      "used     :  5128512.00 MB\n"
     ]
    }
   ],
   "source": [
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(\"GPU 0 stats:\")\n",
    "print(f'total    : {info.total/1024.:>11.2f} MB')\n",
    "print(f'free     : {info.free/1024.:>11.2f} MB')\n",
    "print(f'used     : {info.used/1024.:>11.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383f4c4-583d-428a-800b-1a837bd92839",
   "metadata": {},
   "source": [
    "### FP16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d73a9c3-c950-4021-b743-cf81c01e5b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model 'wav2vec2-ctc.trt' as fp16\n",
      "(1, 312, 32)\n"
     ]
    }
   ],
   "source": [
    "print(f\"loading model '{tensorrt_file_name}' as fp16\")\n",
    "speech_fp16 = np.copy(speech_input).astype(np.float16)\n",
    "model_fp16 = TRTModel(tensorrt_file_name, dtype=np.float16)\n",
    "trt16_prediction = model_fp16(speech_fp16)[0]\n",
    "print(trt16_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9146fe0-acdc-4a13-89f4-9e6908281f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 512/512 [00:05<00:00, 96.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for TensorRT fp16 GPU inference: 10.366 ms per inference\n"
     ]
    }
   ],
   "source": [
    "s = time.perf_counter()\n",
    "for _ in tqdm.trange(test_iters):\n",
    "    out_fp16 = out = model_fp16(speech_fp16)\n",
    "e = time.perf_counter()\n",
    "time.sleep(0.5)\n",
    "trt16_inference = e - s\n",
    "print(f\"time for TensorRT fp16 GPU inference: {trt16_inference*1000./test_iters:.3f} ms per inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937e0b1-948c-4ef0-91a4-915a0621315b",
   "metadata": {},
   "source": [
    "# ======================== EVALUATION ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80366e1b-68b6-4359-8a92-69324e63d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5894ebe0-5443-4185-b871-7e21879a076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_prediction(logits):\n",
    "    logits = np.float32(logits)\n",
    "    return np.argmax(torch.nn.Softmax(dim=-1)(torch.from_numpy(logits)).numpy(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98d43337-39cd-4ad3-8f38-2c005368605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 312, 32)\n",
      "(1, 312, 32)\n",
      "(1, 312, 32)\n",
      "(1, 312, 32)\n",
      "(1, 312, 32)\n"
     ]
    }
   ],
   "source": [
    "print(torch_prediction.shape)\n",
    "print(ort32_prediction.shape)\n",
    "print(ort16_prediction.shape)\n",
    "print(trt32_prediction.shape)\n",
    "print(trt16_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2259556-095e-47b5-bc99-98b8cbd34882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw logit output same as pytorch?\n",
      "ort fp32: False\n",
      "ort fp16: False\n",
      "trt fp32: False\n",
      "trt fp16: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/numeric.py:2366: RuntimeWarning: invalid value encountered in multiply\n",
      "  y = y * ones_like(cond)\n"
     ]
    }
   ],
   "source": [
    "# compare logits (raw outputs)\n",
    "print(\"raw logit output same as pytorch?\")\n",
    "print(\"ort fp32:\", np.allclose(torch_prediction, ort32_prediction, rtol=1e-03, atol=1e-05))\n",
    "print(\"ort fp16:\", np.allclose(torch_prediction, ort16_prediction, rtol=1e-03, atol=1e-05))\n",
    "print(\"trt fp32:\", np.allclose(torch_prediction, trt32_prediction, rtol=1e-03, atol=1e-05))\n",
    "print(\"trt fp16:\", np.allclose(torch_prediction, trt16_prediction, rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be43e9d2-4bd1-4641-afe4-5c66b9e42b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax predictions same as pytorch?\n",
      "ort fp32: True\n",
      "ort fp16: False\n",
      "trt fp32: True\n",
      "trt fp16: False\n"
     ]
    }
   ],
   "source": [
    "# compare softmax argmaxes (predictions)\n",
    "print(\"softmax predictions same as pytorch?\")\n",
    "print(\"ort fp32:\", np.allclose(softmax_prediction(torch_prediction), softmax_prediction(ort32_prediction)))\n",
    "print(\"ort fp16:\", np.allclose(softmax_prediction(torch_prediction), softmax_prediction(ort16_prediction)))\n",
    "print(\"trt fp32:\", np.allclose(softmax_prediction(torch_prediction), softmax_prediction(trt32_prediction)))\n",
    "print(\"trt fp16:\", np.allclose(softmax_prediction(torch_prediction), softmax_prediction(trt16_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66866ebf-0050-4b36-bf7b-1b7d7c8ac5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(softmax_prediction(torch_prediction)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95dda7c8-2f58-476b-bd9f-076602331da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(softmax_prediction(ort32_prediction)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b29550f-bec4-470c-b486-b4858ce5a18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(softmax_prediction(trt32_prediction)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39a573e6-bc35-435f-9559-574ddb26b7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(softmax_prediction(ort16_prediction)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7625c6d3-25b5-483e-9417-e0079498c0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DFFX DYW</s>TX TIWBOKOQIXB BQISKFWYFTQ </s>KWXUIU UYBFOSIUIKBXUU QYUUXOSODQDYYYYQYQUQYQQQYYQQQYYYQYQQQFXWUUF</s>FIDSTDWXKWKITFTFTFBYFDUUX SFWOXBWFWWDYKB YO OX YUQOOSWKW XWSWF</s>OXTYUOOWX'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(softmax_prediction(trt16_prediction)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c54a32a-8907-47a3-8d4d-d54018abcb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ort fp16 CER vs pytorch: 0.28717201166180756\n"
     ]
    }
   ],
   "source": [
    "final_score = cer_metric.compute(predictions=softmax_prediction(ort16_prediction), references=softmax_prediction(torch_prediction))\n",
    "print(\"ort fp16 CER vs pytorch:\", final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "baa43643-cd2a-49b8-a9bc-87067b730392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trt fp16 CER vs pytorch predictions: 0.4912536443148688\n"
     ]
    }
   ],
   "source": [
    "final_score = cer_metric.compute(predictions=softmax_prediction(trt16_prediction), references=softmax_prediction(torch_prediction))\n",
    "print(\"trt fp16 CER vs pytorch predictions:\", final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f366555f-e001-4b1c-8c05-29555b248f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vec 2 results:\n",
      "pytorch      fp32 inference: 12.977 ms per request\n",
      "onnx-runtime fp32 inference: 15.090 ms per request\tresult is close? False\tnan issue?: False\n",
      "onnx-runtime fp16 inference:  7.707 ms per request\tresult is close? False\tnan issue?: False\n",
      "tensorRT     fp32 inference: 10.539 ms per request\tresult is close? False\tnan issue?: False\n",
      "tensorRT     fp16 inference: 10.366 ms per request\tresult is close? False\tnan issue?: True\n"
     ]
    }
   ],
   "source": [
    "print(\"wav2vec 2 results:\")\n",
    "print(f\"pytorch      fp32 inference: {torch_inference*1000./test_iters:>6.3f} ms per request\")\n",
    "print(f\"onnx-runtime fp32 inference: {ort32_inference*1000./test_iters:>6.3f} ms per request\\tresult is close? {np.allclose(torch_prediction, ort32_prediction, rtol=1e-03, atol=1e-05)}\\tnan issue?: {np.isnan(ort32_prediction).any()}\")\n",
    "print(f\"onnx-runtime fp16 inference: {ort16_inference*1000./test_iters:>6.3f} ms per request\\tresult is close? {np.allclose(torch_prediction, ort16_prediction, rtol=1e-03, atol=1e-05)}\\tnan issue?: {np.isnan(ort16_prediction).any()}\")\n",
    "print(f\"tensorRT     fp32 inference: {trt32_inference*1000./test_iters:>6.3f} ms per request\\tresult is close? {np.allclose(torch_prediction, trt32_prediction, rtol=1e-03, atol=1e-05)}\\tnan issue?: {np.isnan(trt32_prediction).any()}\")\n",
    "print(f\"tensorRT     fp16 inference: {trt16_inference*1000./test_iters:>6.3f} ms per request\\tresult is close? {np.allclose(torch_prediction, trt16_prediction, rtol=1e-03, atol=1e-05)}\\tnan issue?: {np.isnan(trt16_prediction).any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7de689-1ccb-47f9-a12f-1ec4a8b872ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
